{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Aggregation Script - calls lab.py and crystals.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reloads the lab.py and crystals.py modules to update any changes (after saving)\n",
    "#If a new method or object is created, autoreload doesn't work and the \n",
    "#kernel needs to be closed and halted after saving and making a 'checkpoint'\n",
    "#in this notebook\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipas \n",
    "import numpy as np\n",
    "import dask\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client, progress\n",
    "from dask import delayed\n",
    "from dask import dataframe as dd\n",
    "import functools\n",
    "import sys\n",
    "import ast\n",
    "from struct import *\n",
    "import pickle\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "import time\n",
    "from dask.distributed import as_completed\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    queue='kratos',\n",
    "    walltime='04-23:00:00',\n",
    "    cores=1,\n",
    "    memory='10000MiB', #1 GiB = 1,024 MiB\n",
    "    processes=1)\n",
    "\n",
    "#cluster.adapt(minimum=3, maximum=20)\n",
    "cluster.scale(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize databases for queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in glob.glob(\"../instance_files/createdb_iceagg_rand*\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape(a,b,c):\n",
    "    if (b-c) <= (a-b):\n",
    "        return 'prolate'\n",
    "    else:\n",
    "        return 'oblate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "data = []\n",
    "for file in files:\n",
    "    print(file)\n",
    "    #dictionary = pickle.load(f)\n",
    "    data.append(pd.read_pickle(file, None))\n",
    "datapd = [pd.DataFrame(i) for i in data]\n",
    "df = pd.concat(datapd, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#speed up shape function \n",
    "vfunc = np.vectorize(shape)\n",
    "df['shape'] = vfunc(df['a'], df['b'], df['c'])\n",
    "df['agg_phi'] = df.c/df.a\n",
    "df = df.reset_index()\n",
    "df.loc[df_rand['shape'] == 'oblate', 'agg_r'] = np.power((np.power(df['a'], 2) * df['c']), (1./3.))\n",
    "df.loc[df_rand['shape'] == 'prolate', 'agg_r'] = np.power((np.power(df['c'], 2) * df['a']), (1./3.))\n",
    "df = df[df.agg_r < 5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_dist='gamma'         #anything other than gamma uses the characteristic from the best distribution pdf (lowest SSE)\n",
    "rand_orient = True      #randomly orient the seed crystal and new crystal: uses first random orientation\n",
    "save_plots = False \n",
    "agg_phi_bins = 20\n",
    "agg_r_bins = 20\n",
    "nclusters = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    output = np.empty((agg_phi_bins,agg_r_bins),dtype=object)\n",
    "    hold_clusters1  = np.empty((agg_phi_bins,agg_r_bins,nclusters), dtype=object)\n",
    "    hold_clusters2  = np.empty((agg_phi_bins,agg_r_bins,nclusters), dtype=object)\n",
    "\n",
    "    res, phi_bins = pd.qcut(df.agg_phi, agg_phi_bins, retbins=True)\n",
    "\n",
    "    for i in range(1, agg_phi_bins):\n",
    "        #print('agg phi range: ', phi_bins[i], phi_bins[i+1])\n",
    "        #return a df that only queries within an aspect ratio bin\n",
    "        df_phi = df[(df.agg_phi > phi_bins[i]) & (df.agg_phi < phi_bins[i+1])]  \n",
    "        #to ensure at least 2 crystals within agg since ncrystals=1 not in db\n",
    "        #now break that aspect ratio bin into 20 equal r bins\n",
    "        \n",
    "        res, r_bins = pd.qcut(df_phi.agg_r, agg_r_bins, retbins=True)\n",
    "        for r in range(agg_r_bins):   #agg r\n",
    "               \n",
    "            #print('r = ', r_bins[r], r_bins[r+1])\n",
    "            df_r = df_phi[(df_phi.agg_r > r_bins[r]) & (df_phi.agg_r < r_bins[r+1])]\n",
    "            #plt.hist(df_r.mono_phi)\n",
    "            #plt.xscale('log')\n",
    "            #plt.show()\n",
    "\n",
    "            samples1 = df_r.sample(nclusters)\n",
    "            samples2 = df_r.sample(nclusters)\n",
    "            \n",
    "            for n, agg in enumerate(samples1.itertuples()):\n",
    "                hold_clusters1[i,r,n] = ipas.Cluster_Calculations(agg)\n",
    "            for n, agg in enumerate(samples2.itertuples()):\n",
    "                hold_clusters2[i,r,n] = ipas.Cluster_Calculations(agg)\n",
    "            ipas.collect_clusters(hold_clusters1[i,r,:], hold_clusters2[i,r,:], rand_orient=rand_orient)\n",
    "            #output[i,r] = dask.delayed(ipas.collect_clusters)(hold_clusters1[i,r,:],\n",
    "            #                                                     hold_clusters2[i,r,:], rand_orient=rand_orient)\n",
    "\n",
    "    return output, hold_clusters1, hold_clusters2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute():\n",
    "    agg_as = np.empty((agg_phi_bins, agg_r_bins, nclusters))\n",
    "    agg_bs = np.empty((agg_phi_bins, agg_r_bins, nclusters))\n",
    "    rzs = np.empty((agg_phi_bins, agg_r_bins, nclusters))\n",
    "    phi2Ds = np.empty((agg_phi_bins, agg_r_bins, nclusters))\n",
    "    cplxs = np.empty((agg_phi_bins, agg_r_bins, nclusters))\n",
    "    dds = np.empty((agg_phi_bins, agg_r_bins, nclusters))\n",
    "\n",
    "    gather = client.compute([*output.tolist()]) \n",
    "    gather = client.gather(gather)\n",
    "    gather = np.array(gather)\n",
    "    print(np.shape(gather))\n",
    "    agg_as = gather[:,:,0,:]\n",
    "    agg_bs = gather[:,:,1,:]\n",
    "    agg_cs = gather[:,:,2,:]\n",
    "    phi2Ds = gather[:,:,3,:]\n",
    "    cplxs = gather[:,:,4,:] \n",
    "    dds = gather[:,:,5,:]\n",
    "\n",
    "    print('DONE!')\n",
    "    return agg_as, agg_bs, agg_cs, phi2Ds, cplxs, dds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    output, hold_clusters1, hold_clusters2 = main()\n",
    "    agg_as, agg_bs, agg_cs, phi2Ds, cplxs, dds= compute()\n",
    "    results = {'agg_as': agg_as, 'agg_bs':agg_bs, 'agg_cs':agg_cs, 'phi2Ds':phi2Ds, \\\n",
    "               'cplxs':cplxs, 'dds':dds}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../instance_files/pulled_clusters_aggagg_rand'\n",
    "filehandler = open(filename, 'wb')\n",
    "to_file = np.append(hold_clusters1, hold_clusters2).reshape(20,20,nclusters*2)\n",
    "pickle.dump(to_file, filehandler)\n",
    "filehandler.close()\n",
    "print('finished!')\n",
    "\n",
    "filename = '../instance_files/instance_db_aggagg_rand'\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(results, filehandler)\n",
    "filehandler.close()\n",
    "print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../instance_files/instance_db_aggagg_rand', 'rb')\n",
    "results = pickle.load(f)\n",
    "agg_as, agg_bs, agg_cs, phi2Ds, cplxs, dds= \\\n",
    "                results['agg_as'], results['agg_bs'], results['agg_cs'], results['phi2Ds'], results['cplxs'], results['dds']\n",
    "f.close()\n",
    "\n",
    "f = open('../instance_files/pulled_clusters_aggagg_rand', 'rb')\n",
    "pulled_clus = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../instance_files/pulled_clusters_iceagg_flat', 'rb')\n",
    "pulled_clus = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulled_clus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulled_clus[0,0,0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for phi in range(pulled_clus.shape[0]):\n",
    "    for r in range(pulled_clus.shape[1]):\n",
    "        for n in range(pulled_clus.shape[2]):\n",
    "            if pulled_clus[phi,r,n].monophi>70.:\n",
    "                count+=1\n",
    "print(count/(20*20*600)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for phi in range(pulled_clus.shape[0]):\n",
    "    for r in range(pulled_clus.shape[1]):\n",
    "        for n in range(pulled_clus.shape[2]):\n",
    "            if pulled_clus[phi,r,n].monophi<.1:\n",
    "                count+=1\n",
    "print(count/(20*20*600)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "IPAS",
   "language": "python",
   "name": "ipas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
