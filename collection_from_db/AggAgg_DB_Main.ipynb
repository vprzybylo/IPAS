{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Aggregation Script - calls lab.py and crystals.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reloads the lab.py and crystals.py modules to update any changes (after saving)\n",
    "#If a new method or object is created, autoreload doesn't work and the \n",
    "#kernel needs to be closed and halted after saving and making a 'checkpoint'\n",
    "#in this notebook\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipas \n",
    "import numpy as np\n",
    "import dask\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client, progress\n",
    "from dask import delayed\n",
    "from dask import dataframe as dd\n",
    "import functools\n",
    "import sys\n",
    "import ast\n",
    "from struct import *\n",
    "import pickle\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "import time\n",
    "from dask.distributed import as_completed\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/network/rit/lab/sulialab/share/bin/miniconda3/envs/pangeo/lib/python3.6/site-packages/distributed/dashboard/core.py:72: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    }
   ],
   "source": [
    "cluster = SLURMCluster(\n",
    "    queue='kratos',\n",
    "    walltime='04-23:00:00',\n",
    "    cores=1,\n",
    "    memory='10000MiB', #1 GiB = 1,024 MiB\n",
    "    processes=1)\n",
    "\n",
    "#cluster.adapt(minimum=3, maximum=20)\n",
    "cluster.scale(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://169.226.65.160:37835</li>\n",
       "  <li><b>Dashboard: </b><a href='http://169.226.65.160:38031/status' target='_blank'>http://169.226.65.160:38031/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://169.226.65.160:37835' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize databases for queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in glob.glob(\"../instance_files/createdb_iceagg_rand*\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape(a,b,c):\n",
    "    if (b-c) <= (a-b):\n",
    "        return 'prolate'\n",
    "    else:\n",
    "        return 'oblate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../instance_files/createdb_iceagg_rand_r500_1000\n",
      "../instance_files/createdb_iceagg_rand_r1_5\n",
      "../instance_files/createdb_iceagg_rand_r6_10\n",
      "../instance_files/createdb_iceagg_rand_r20_70\n",
      "../instance_files/createdb_iceagg_rand_r80_400\n",
      "CPU times: user 1min 12s, sys: 25.8 s, total: 1min 38s\n",
      "Wall time: 3min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "data = []\n",
    "for file in files:\n",
    "    print(file)\n",
    "    #dictionary = pickle.load(f)\n",
    "    data.append(pd.read_pickle(file, None))\n",
    "datapd = [pd.DataFrame(i) for i in data]\n",
    "df = pd.concat(datapd, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['agg_r'] = np.power((np.power(df['a'], 2) * df['c']), (1./3.))\n",
    "df = df[df.agg_r < 5000]\n",
    "#speed up shape function \n",
    "vfunc = np.vectorize(shape)\n",
    "df['shape'] = vfunc(df['a'], df['b'], df['c'])\n",
    "df['agg_phi'] = df.c/df.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amax(df['cplx']), np.amin(df['cplx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in glob.glob(\"../instance_files/createdb_iceagg_rand*\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "data = []\n",
    "for file in files:\n",
    "    print(file)\n",
    "    #dictionary = pickle.load(f)\n",
    "    data.append(pd.read_pickle(file, None))\n",
    "datapd = [pd.DataFrame(i) for i in data]\n",
    "df = pd.concat(datapd, axis=0, ignore_index=True)\n",
    "df['agg_r'] = np.power((np.power(df['a'], 2) * df['c']), (1./3.))\n",
    "df['agg_r'] = df['agg_r'][df.agg_r < 5000]\n",
    "df['shape'] = df.apply(lambda row: 'prolate' if (row.b - row.c) <= (row.a - row.b) else 'oblate', axis=1)\n",
    "df['agg_phi'] = df.c/df.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_dist='gamma'         #anything other than gamma uses the characteristic from the best distribution pdf (lowest SSE)\n",
    "rand_orient = True      #randomly orient the seed crystal and new crystal: uses first random orientation\n",
    "save_plots = False \n",
    "agg_phi_bins = 20\n",
    "agg_r_bins = 20\n",
    "nclusters = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    output = np.empty((agg_phi_bins,agg_r_bins),dtype=object)\n",
    "    hold_clusters1  = np.empty((agg_phi_bins,agg_r_bins,nclusters), dtype=object)\n",
    "    hold_clusters2  = np.empty((agg_phi_bins,agg_r_bins,nclusters), dtype=object)\n",
    "\n",
    "    res, phi_bins = pd.qcut(df.agg_phi, agg_phi_bins, retbins=True)\n",
    "\n",
    "    for i in range(1, agg_phi_bins):\n",
    "        #print('agg phi range: ', phi_bins[i], phi_bins[i+1])\n",
    "        #return a df that only queries within an aspect ratio bin\n",
    "        df_phi = df[(df.agg_phi > phi_bins[i]) & (df.agg_phi < phi_bins[i+1])]  \n",
    "        #to ensure at least 2 crystals within agg since ncrystals=1 not in db\n",
    "        #now break that aspect ratio bin into 20 equal r bins\n",
    "        \n",
    "        res, r_bins = pd.qcut(df_phi.agg_r, agg_r_bins, retbins=True)\n",
    "        for r in range(agg_r_bins):   #agg r\n",
    "               \n",
    "            #print('r = ', r_bins[r], r_bins[r+1])\n",
    "            df_r = df_phi[(df_phi.agg_r > r_bins[r]) & (df_phi.agg_r < r_bins[r+1])]\n",
    "            #plt.hist(df_r.mono_phi)\n",
    "            #plt.xscale('log')\n",
    "            #plt.show()\n",
    "\n",
    "            samples1 = df_r.sample(nclusters)\n",
    "            samples2 = df_r.sample(nclusters)\n",
    "            \n",
    "            for n, agg in enumerate(samples1.itertuples()):\n",
    "                hold_clusters1[i,r,n] = ipas.Cluster_Calculations(agg)\n",
    "            for n, agg in enumerate(samples2.itertuples()):\n",
    "                hold_clusters2[i,r,n] = ipas.Cluster_Calculations(agg)\n",
    "            ipas.collect_clusters(hold_clusters1[i,r,:], hold_clusters2[i,r,:], rand_orient=rand_orient)\n",
    "            #output[i,r] = dask.delayed(ipas.collect_clusters)(hold_clusters1[i,r,:],\n",
    "            #                                                     hold_clusters2[i,r,:], rand_orient=rand_orient)\n",
    "\n",
    "    return output, hold_clusters1, hold_clusters2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute():\n",
    "    agg_as = np.empty((agg_phi_bins, agg_r_bins, nclusters))\n",
    "    agg_bs = np.empty((agg_phi_bins, agg_r_bins, nclusters))\n",
    "    rzs = np.empty((agg_phi_bins, agg_r_bins, nclusters))\n",
    "    phi2Ds = np.empty((agg_phi_bins, agg_r_bins, nclusters))\n",
    "    cplxs = np.empty((agg_phi_bins, agg_r_bins, nclusters))\n",
    "    dds = np.empty((agg_phi_bins, agg_r_bins, nclusters))\n",
    "\n",
    "    gather = client.compute([*output.tolist()]) \n",
    "    gather = client.gather(gather)\n",
    "    gather = np.array(gather)\n",
    "    print(np.shape(gather))\n",
    "    agg_as = gather[:,:,0,:]\n",
    "    agg_bs = gather[:,:,1,:]\n",
    "    agg_cs = gather[:,:,2,:]\n",
    "    phi2Ds = gather[:,:,3,:]\n",
    "    cplxs = gather[:,:,4,:] \n",
    "    dds = gather[:,:,5,:]\n",
    "\n",
    "    print('DONE!')\n",
    "    return agg_as, agg_bs, agg_cs, phi2Ds, cplxs, dds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "collect_clusters() missing 1 required positional argument: 'clusters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-314f4fa0f65d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhold_clusters1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhold_clusters2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0magg_as\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magg_bs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magg_cs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi2Ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcplxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdds\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'agg_as'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0magg_as\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'agg_bs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0magg_bs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'agg_cs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0magg_cs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'phi2Ds'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mphi2Ds\u001b[0m\u001b[0;34m,\u001b[0m                \u001b[0;34m'cplxs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcplxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dds'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdds\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-894cef1bec60>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitertuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mhold_clusters2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mipas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCluster_Calculations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mipas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhold_clusters1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhold_clusters2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_orient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrand_orient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0;31m#output[i,r] = dask.delayed(ipas.collect_clusters)(hold_clusters1[i,r,:],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m#                                                     hold_clusters2[i,r,:], rand_orient=rand_orient)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: collect_clusters() missing 1 required positional argument: 'clusters'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    output, hold_clusters1, hold_clusters2 = main()\n",
    "    agg_as, agg_bs, agg_cs, phi2Ds, cplxs, dds= compute()\n",
    "    results = {'agg_as': agg_as, 'agg_bs':agg_bs, 'agg_cs':agg_cs, 'phi2Ds':phi2Ds, \\\n",
    "               'cplxs':cplxs, 'dds':dds}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../instance_files/pulled_clusters_aggagg_rand'\n",
    "filehandler = open(filename, 'wb')\n",
    "to_file = np.append(hold_clusters1, hold_clusters2).reshape(20,20,nclusters*2)\n",
    "pickle.dump(to_file, filehandler)\n",
    "filehandler.close()\n",
    "print('finished!')\n",
    "\n",
    "filename = '../instance_files/instance_db_aggagg_rand'\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(results, filehandler)\n",
    "filehandler.close()\n",
    "print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../instance_files/instance_db_aggagg_rand', 'rb')\n",
    "results = pickle.load(f)\n",
    "agg_as, agg_bs, agg_cs, phi2Ds, cplxs, dds= \\\n",
    "                results['agg_as'], results['agg_bs'], results['agg_cs'], results['phi2Ds'], results['cplxs'], results['dds']\n",
    "f.close()\n",
    "\n",
    "f = open('../instance_files/pulled_clusters_aggagg_rand', 'rb')\n",
    "pulled_clus = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "IPAS",
   "language": "python",
   "name": "ipas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
