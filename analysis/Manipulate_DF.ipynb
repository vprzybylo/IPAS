{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask as dask\n",
    "from dask import dataframe as dd\n",
    "import numpy as np\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client\n",
    "import dask.array as da\n",
    "import functools\n",
    "import sys\n",
    "import ast\n",
    "from struct import *\n",
    "import pickle\n",
    "import glob\n",
    "import random\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    queue='kratos',\n",
    "    walltime='04-23:00:00',\n",
    "    cores=1,\n",
    "    memory='7000MiB', #1 GiB = 1,024 MiB\n",
    "    processes=1)\n",
    "\n",
    "cluster.scale(10)\n",
    "#cluster.adapt(minimum=3, maximum=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.49 s, sys: 585 ms, total: 5.07 s\n",
      "Wall time: 4.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#READ DATABASE FOR RANDOM ORIENTATION\n",
    "df = dd.read_parquet(\"../instance_files/parquet_files/createdb_iceagg_rand*\", engine=\"pyarrow\").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4872000 entries, 0 to 1043999\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   ncrystals  int64  \n",
      " 1   mono_phi   float64\n",
      " 2   mono_r     int64  \n",
      " 3   a          float64\n",
      " 4   b          float64\n",
      " 5   c          float64\n",
      " 6   phi2D      float64\n",
      " 7   cplx       float64\n",
      "dtypes: float64(6), int64(2)\n",
      "memory usage: 334.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#OLD WAY OF READING DATABASE \n",
    "files = ['sqlite:///'+f for f in glob.glob(\"../db_files/IPAS_*_flat.sqlite\")]\n",
    "tables = ['aggregates', 'crystals']\n",
    "df=[]\n",
    "for table in tables:\n",
    "    \n",
    "    #read tables in parallel on client \n",
    "    read_files = [dask.delayed(dd.read_sql_table)(table=table, uri=file, index_col='id') for file in files]\n",
    "    \n",
    "    compute_read = client.compute(read_files)\n",
    "    print('done with compute')\n",
    "    ddfs = client.gather(compute_read)\n",
    "    print('done with gather')\n",
    "    #concatenate all sqlite files vertically (axis=0 default) (same columns)\n",
    "    gathered_reads = client.scatter(ddfs)\n",
    "    ddf = client.submit(dd.concat, gathered_reads).result()\n",
    "    print('done with submit')\n",
    "    #append combined dask df for each table\n",
    "    df.append(ddf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory info and df stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[1].info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see partitions\n",
    "print(df[0].npartitions)\n",
    "print(df[1].npartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[0]), len(df[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = client.persist(df[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mono = client.persist(df[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_stats = df[0]['agg_phi'].describe().round(2).compute()\n",
    "agg_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_stats = df[0]['agg_r'].describe().round(2).compute()\n",
    "r_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_stats = df[1]['r'].describe().round(2).compute()\n",
    "r_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_stats = df[1]['phi'].describe().round(2).compute()\n",
    "phi_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[1].columns\n",
    "#phi_stats = df[1]['phi'].describe().round(2).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(df_crys[df_crys.r == 50])\n",
    "# frequency count of mono r\n",
    "count = df[1].r.value_counts() \n",
    "# Multi-column frequency count \n",
    "count = df_repart.groupby(['agg_phi']).count().compute()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat, Repartition, and Clean Up DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time df_concat = dd.concat([df[0], df[1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.agg_r = np.power((np.power(df_concat.a, 2) * df_concat.c), (1./3.))\n",
    "df_concat.agg_phi = 1/df_concat.agg_phi\n",
    "agg_stats = df_concat['agg_phi'].describe().round(2).compute()\n",
    "agg_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_r_5000(df):\n",
    "    return df[(df.agg_r > 5000)]\n",
    "\n",
    "df_concat_query = df_concat.map_partitions(query_r_5000)\n",
    "len(df_concat_query) #86% of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repart = df_concat.repartition(partition_size=\"100MB\").persist()\n",
    "df_repart.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_stats = df_repart['agg_phi'].describe().round(2).compute()\n",
    "agg_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_concat._meta.dtypes\n",
    "#df_concat.divisions\n",
    "print(df_concat.npartitions)\n",
    "print(df_concat.memory_usage(deep=True).sum().compute() / 1024**2)  #5.1 GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test agg agg queries for collection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_repart.agg_phi.compute(), bins =10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FLAT\n",
    "file = open('../instance_files/instance_db_aggagg_flat_returnclus1', 'rb')\n",
    "bflat = pickle.load(file)\n",
    "\n",
    "#a=z b=y c=x\n",
    "\n",
    "#dunnavan: a>= b >= c\n",
    "#in our case z >= y >= x\n",
    "\n",
    "nclusters = 300\n",
    "rxs_flat = np.zeros((20,20,nclusters))\n",
    "rys_flat = np.zeros((20,20,nclusters))\n",
    "rzs_flat = np.zeros((20,20,nclusters))\n",
    "phi2Ds_flat = np.zeros((20,20,nclusters))\n",
    "cplxs_flat = np.zeros((20,20,nclusters))\n",
    "dds_flat = np.zeros((20,20,nclusters))\n",
    "cluster1_ncrystals_flat = np.zeros((20,20,nclusters))\n",
    "cluster2_ncrystals_flat = np.zeros((20,20,nclusters))\n",
    "\n",
    "counter=0\n",
    "for phi in range(20):\n",
    "    for r in range(20):\n",
    "        rxs_flat[phi, r, :] = np.array(bflat[counter][0])[:,0]\n",
    "        rys_flat[phi, r, :] = np.array(bflat[counter][0])[:,1]\n",
    "        rzs_flat[phi, r, :] = np.array(bflat[counter][0])[:,2]\n",
    "        phi2Ds_flat[phi, r, :] = bflat[counter][1]\n",
    "        cplxs_flat[phi, r, :] = bflat[counter][2]\n",
    "        dds_flat[phi, r, :] = bflat[counter][3]\n",
    "        cluster1_ncrystals_flat[phi, r, :] = bflat[counter][4]\n",
    "        cluster2_ncrystals_flat[phi, r, :]= bflat[counter][5]\n",
    "        counter+=1\n",
    "phiba_flat = rys_flat/rzs_flat\n",
    "phica_flat = rxs_flat/rzs_flat\n",
    "\n",
    "print(np.max(cplxs_flat), np.min(cplxs_flat[cplxs_flat!=-999.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAND\n",
    "file = open('../instance_files/instance_db_aggagg_rand_returnclus1', 'rb')\n",
    "brand = pickle.load(file)\n",
    "\n",
    "#a=z b=y c=x\n",
    "\n",
    "#dunnavan: a>= b >= c\n",
    "#in our case z >= y >= x\n",
    "\n",
    "nclusters = 300\n",
    "rxs_rand = np.zeros((20,20,nclusters))\n",
    "rys_rand = np.zeros((20,20,nclusters))\n",
    "rzs_rand = np.zeros((20,20,nclusters))\n",
    "phi2Ds_rand = np.zeros((20,20,nclusters))\n",
    "cplxs_rand = np.zeros((20,20,nclusters))\n",
    "dds_rand = np.zeros((20,20,nclusters))\n",
    "cluster1_ncrystals_rand = np.zeros((20,20,nclusters))\n",
    "cluster2_ncrystals_rand = np.zeros((20,20,nclusters))\n",
    "\n",
    "counter=0\n",
    "for phi in range(20):\n",
    "    for r in range(20):\n",
    "        rxs_rand[phi, r, :] = np.array(brand[counter][0])[:,0]\n",
    "        rys_rand[phi, r, :] = np.array(brand[counter][0])[:,1]\n",
    "        rzs_rand[phi, r, :] = np.array(brand[counter][0])[:,2]\n",
    "        phi2Ds_rand[phi, r, :] = brand[counter][1]\n",
    "        cplxs_rand[phi, r, :] = brand[counter][2]\n",
    "        dds_rand[phi, r, :] = brand[counter][3]\n",
    "        cluster1_ncrystals_rand[phi, r, :] = brand[counter][4]\n",
    "        cluster2_ncrystals_rand[phi, r, :]= brand[counter][5]\n",
    "        counter+=1\n",
    "phiba_rand = rys_rand/rzs_rand\n",
    "phica_rand = rxs_rand/rzs_rand\n",
    "#np.shape(phica_rand)\n",
    "print(np.max(cplxs_rand), np.min(cplxs_rand[cplxs_rand!=-999.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FLAT Ncrystals\n",
    "file = open('instance_files/pulled_clusters_flat1', 'rb')\n",
    "bflat = pickle.load(file)\n",
    "\n",
    "nclusters = 301\n",
    "cluster1_ncrystals_flat = np.zeros((20,20,nclusters))\n",
    "\n",
    "counter=0\n",
    "for phi in range(20):\n",
    "    for r in range(20):\n",
    "        for n in range(301):\n",
    "            cluster1_ncrystals_flat[phi, r, :] = [n.ncrystals for n in bflat[phi, r, :]]\n",
    "\n",
    "        counter+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FLAT Ncrystals\n",
    "file = open('instance_files/pulled_clusters_rand', 'rb')\n",
    "brand = pickle.load(file)\n",
    "\n",
    "nclusters = 301\n",
    "cluster1_ncrystals_rand = np.zeros((20,20,nclusters))\n",
    "\n",
    "counter=0\n",
    "for phi in range(20):\n",
    "    for r in range(20):\n",
    "        for n in range(301):\n",
    "            cluster1_ncrystals_rand[phi, r, :] = [n.ncrystals for n in brand[phi, r, :]]\n",
    "\n",
    "        counter+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_ncrystals(df_phi, r_bins):\n",
    "    avg_ncrystals = []\n",
    "    for r in range(len(r_bins)-1):\n",
    "        df = df_phi[(df_phi.agg_r > r_bins[r]) & (df_phi.agg_r < r_bins[r+1])]\n",
    "        avg_ncrystals.append(df.r.mean().compute())\n",
    "    return avg_ncrystals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_ncrystals_afteragg(df_phi, r_bins):\n",
    "    avg_ncrystals = []\n",
    "    for r in range(len(r_bins)-1):\n",
    "        avg_ncrystals.append(np.mean(cluster1_ncrystals_flat[i,r,:])+np.mean(cluster2_ncrystals_flat[i,r,:]))\n",
    "    return avg_ncrystals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_cplx(i, r_bins):\n",
    "    avg_cplx = []\n",
    "    for r in range(len(r_bins)-1):\n",
    "        avg_cplx.append(np.mean(cplxs_flat[i,r,:]))\n",
    "    return avg_cplx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FLAT\n",
    "res, phi_bins_flat = pd.qcut(df_repart.agg_phi.compute(), 20, retbins=True)\n",
    "%store phi_bins_flat\n",
    "#print(phi_bins)\n",
    "phi_bin_labs = []\n",
    "avg_ncrystals=np.empty((len(phi_bins_flat)-1,len(phi_bins_flat)-1))\n",
    "avg_cplxs=np.empty((len(phi_bins_flat)-1,len(phi_bins_flat)-1))\n",
    "all_r_bins_flat = np.empty((len(phi_bins_flat),len(phi_bins_flat)))\n",
    "\n",
    "\n",
    "for i in range(len(phi_bins_flat)-1):\n",
    "    print('i = ', i)\n",
    "    phi_bin_labs.append('[%.3f-%.3f]' %(phi_bins_flat[i],phi_bins_flat[i+1]))\n",
    "    #return a df that only queries within an aspect ratio bin\n",
    "    df_phi = df_repart[(df_repart.agg_phi > phi_bins_flat[i]) & (df_repart.agg_phi < phi_bins_flat[i+1])]\n",
    "    #now break that aspect ratio bin into 20 equal r bins\n",
    "    res, r_bins_flat = pd.qcut(df_phi.agg_r.compute(), 20, retbins=True)\n",
    "    \n",
    "    all_r_bins_flat[i,:]=r_bins_flat\n",
    "    #now use those r bins from the output of queried r and phi to find # of monomers per bin\n",
    "    avg_ncrystals[i,:] = query_ncrystals(df_phi, r_bins_flat)\n",
    "    avg_ncrystals[i,:] = avg_ncrystals_afteragg(i, r_bins_flat)\n",
    "    avg_cplxs[i,:] = avg_cplx(i, r_bins_flat)\n",
    "    \n",
    "%store all_r_bins_flat    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAND\n",
    "res, phi_bins_rand = pd.qcut(df_repart.agg_phi.compute(), 20, retbins=True)\n",
    "%store phi_bins_rand\n",
    "#print(phi_bins)\n",
    "phi_bin_labs = []\n",
    "avg_ncrystals=np.empty((len(phi_bins_rand)-1,len(phi_bins_rand)-1))\n",
    "avg_cplxs=np.empty((len(phi_bins_rand)-1,len(phi_bins_rand)-1))\n",
    "all_r_bins_rand = np.empty((len(phi_bins_rand),len(phi_bins_rand)))\n",
    "\n",
    "\n",
    "for i in range(len(phi_bins_rand)-1):\n",
    "    print('i = ', i)\n",
    "    phi_bin_labs.append('[%.3f-%.3f]' %(phi_bins_rand[i],phi_bins_rand[i+1]))\n",
    "    #return a df that only queries within an aspect ratio bin\n",
    "    df_phi = df_repart[(df_repart.agg_phi > phi_bins_rand[i]) & (df_repart.agg_phi < phi_bins_rand[i+1])]\n",
    "    #now break that aspect ratio bin into 20 equal r bins\n",
    "    res, r_bins_rand = pd.qcut(df_phi.agg_r.compute(), 20, retbins=True)\n",
    "    \n",
    "    all_r_bins_rand[i,:] = r_bins_rand\n",
    "    #now use those r bins from the output of queried r and phi to find # of monomers per bin\n",
    "    avg_ncrystals[i,:] = query_ncrystals(df_phi, r_bins_rand)\n",
    "    avg_ncrystals[i,:] = avg_ncrystals_afteragg(i, r_bins_rand)\n",
    "    avg_cplxs[i,:] = avg_cplx(i, r_bins_rand)\n",
    "    \n",
    "%store all_r_bins_rand    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "cmap = plt.cm.jet\n",
    "# vmin=np.amin(avg_cplxs)\n",
    "# vmax=np.amax(avg_cplxs)\n",
    "# print(vmin, vmax) \n",
    "#1.3914486210085406 907.974759288473   flat r max min\n",
    "#1.2451487710219922 640.6597671410091  rand r\n",
    "\n",
    "#flat\n",
    "#mono_r = vmin=np.amin(avg_ncrystals), vmax=np.amax(avg_ncrystals)\n",
    "#norm = matplotlib.colors.LogNorm(vmin=1.2, vmax=900)\n",
    "norm = matplotlib.colors.Normalize(vmin=4, vmax=100)\n",
    "\n",
    "#norm = matplotlib.colors.LogNorm(vmin=0.5, vmax=1.0)\n",
    "\n",
    "for i in range(len(phi_bins)-1): \n",
    "    print('i= ', i)\n",
    "    for r in range(len(r_bins)-2):\n",
    "        if r != 0:\n",
    "            plt.bar([i]*len(r_bins), all_r_bins[i,r], bottom= all_r_bins[i,r-1],  color=cmap(norm(np.mean(cluster1_ncrystals_flat[i,r,:]+cluster2_ncrystals_flat[i,r,:]))),edgecolor='k')\n",
    "\n",
    "        else:\n",
    "            plt.bar([i]*len(r_bins), all_r_bins[i,r], color=cmap(norm(np.mean(cluster1_ncrystals_flat[i,r,:]+cluster2_ncrystals_flat[i,r,:]))), edgecolor='k')\n",
    "        \n",
    "#     for x,y in zip([i]*len(r_bins), r_bins):\n",
    "\n",
    "#         label = \"{:.2f}\".format(y)\n",
    "\n",
    "#         plt.annotate(label, # this is the text\n",
    "#                      (x,y), # this is the point to label\n",
    "#                      textcoords=\"offset points\", # how to position the text\n",
    "#                      xytext=(0,1), # distance from text to points (x,y)\n",
    "#                      ha='center') # horizontal alignment can be left, right or center\n",
    "\n",
    "    \n",
    "plt.yscale('log')\n",
    "plt.xticks(np.arange(len(phi_bin_labs)), phi_bin_labs, rotation=90, ha=\"center\",fontsize=16,family='serif')\n",
    "plt.ylabel(\"Aggregate Radius Bins\",fontsize=16,family='serif')\n",
    "plt.xlabel(\"Aggregate Aspect Ratio ($\\phi$) bins\",fontsize=16,family='serif')  \n",
    "cb = plt.cm.ScalarMappable(cmap=cmap)\n",
    "cbar = plt.colorbar(cb,format='%.2f')\n",
    "#cbar.ax.set_ylabel('Average # of monomers per bin', fontsize=16, family='serif')\n",
    "cbar.ax.set_ylabel('Average # of monomers per bin', fontsize=16, family='serif')\n",
    "#plt.title('Quasi-Horizontal Orientation',fontsize=16, family='serif')\n",
    "plt.title('Flat Orientation',fontsize=16, family='serif')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('bins_rand_meanmono_r_5000rad_logy.pdf')\n",
    "\n",
    "#sm.set_label('Average # of monomers in the aggregates')\n",
    "#textstr = '$n$ values per $phi$ :', str(res.value_counts()[0])\n",
    "#ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=14,\n",
    "#        vertical alignment='top', bbox=dict(boxstyle='round'))\n",
    "#17716 values per phi, per r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#switch a and c\n",
    "col_list = list(df_repart)\n",
    "print(col_list)\n",
    "col_list[3], col_list[5] = col_list[5], col_list[3]\n",
    "# assign back, the order will now be swapped\n",
    "df_repart.columns = col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# df_repart['c'] = pd.DataFrame([df_repart['a'], df_repart.c]).min(axis=1)\n",
    "# df_repart['a'] = pd.DataFrame([df_repart['a'], df_repart.c]).max(axis=1)\n",
    "df_repart['agg_phi'] = df_repart.c/df_repart.a\n",
    "df_repart['shape'] = df_repart.apply(lambda row: 'prolate' if (row.b - row.c) <= (row.a - row.b) else 'oblate', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "res, phi_bins = pd.qcut(df_repart.agg_phi.compute(), 20, retbins=True)\n",
    "shape = np.empty((len(phi_bins), len(r_bins)), dtype=str)\n",
    "print(phi_bins)\n",
    "for i in range(len(phi_bins)-1):\n",
    "    print('i = ', phi_bins[i], phi_bins[i+1])\n",
    "    #return a df that only queries within an aspect ratio bin\n",
    "    df_phi = df_repart[(df_repart.agg_phi > phi_bins[i]) & (df_repart.agg_phi < phi_bins[i+1])]\n",
    "    #now break that aspect ratio bin into 20 equal r bins\n",
    "    res, r_bins = pd.qcut(df_phi.agg_r.compute(), 20, retbins=True)\n",
    "    for r in range(len(r_bins)-1):\n",
    "        print('r =', r_bins[r], r_bins[r+1])\n",
    "        df_r = df_phi[(df_phi.agg_r > r_bins[r]) & (df_phi.agg_r < r_bins[r+1])].compute() \n",
    "\n",
    "        oblates = df_r['shape'][df_r['shape'] == 'oblate'].count()\n",
    "        prolates = df_r['shape'][df_r['shape'] == 'prolate'].count()\n",
    "       \n",
    "        print(oblates, prolates)\n",
    "        shape[i,r] = 'oblates' if oblates > prolates else 'prolates'\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oblates = df_repart['shape'][df_repart['shape']  == 'oblate'].count().compute()\n",
    "prolates = df_repart['shape'][df_repart['shape']  == 'prolate'].count().compute()\n",
    "print(oblates, prolates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
