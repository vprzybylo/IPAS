{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask as dask\n",
    "from dask import dataframe as dd\n",
    "import numpy as np\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client\n",
    "import dask.array as da\n",
    "import functools\n",
    "import sys\n",
    "import ast\n",
    "from struct import *\n",
    "import pickle\n",
    "import glob\n",
    "import random\n",
    "import seaborn as snsa\n",
    "import ipywidgets as widgets\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    queue='kratos',\n",
    "    walltime='04-23:00:00',\n",
    "    cores=1,\n",
    "    memory='20000MiB', #1 GiB = 1,024 MiB\n",
    "    processes=1)\n",
    "\n",
    "#cluster.adapt(minimum=3, maximum=20)\n",
    "cluster.scale(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['sqlite:///'+f for f in glob.glob(\"db_files/IPAS_*_flat.sqlite\")]\n",
    "tables = ['aggregates', 'crystals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df=[]\n",
    "for table in tables:\n",
    "    \n",
    "    #read tables in parallel on client \n",
    "    read_files = [dask.delayed(dd.read_sql_table)(table=table, uri=file, index_col='id') for file in files]\n",
    "    \n",
    "    compute_read = client.compute(read_files)\n",
    "    print('done with compute')\n",
    "    ddfs = client.gather(compute_read)\n",
    "    print('done with gather')\n",
    "    #concatenate all sqlite files vertically (axis=0 default) (same columns)\n",
    "    gathered_reads = client.scatter(ddfs)\n",
    "    ddf = client.submit(dd.concat, gathered_reads).result()\n",
    "    print('done with submit')\n",
    "    #append combined dask df for each table\n",
    "    df.append(ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get phi/r bins \n",
    "df_concat = dd.concat([df[0], df[1]], axis=1)\n",
    "df_concat.agg_r = np.power((np.power(df_concat.a, 2) * df_concat.c), (1./3.))\n",
    "def query_r_5000(df):\n",
    "    return df[df.agg_r < 5000]\n",
    "\n",
    "df_concat = df_concat.map_partitions(query_r_5000)\n",
    "df_repart = df_concat.repartition(partition_size=\"100MB\").persist()\n",
    "df_repart.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flat\n",
    "df_repart.agg_phi.describe().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rand\n",
    "df_repart.agg_phi.describe().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repart[df_repart.agg_phi > 70].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_phi_bins, agg_r_bins = 20, 20\n",
    "\n",
    "res, phi_bins = pd.qcut(df_repart.agg_phi.compute(), agg_phi_bins, retbins=True)\n",
    "phi_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_phi_bins, agg_r_bins = 20, 20\n",
    "\n",
    "res, phi_bins1 = pd.qcut(df_repart.agg_phi[df_repart.agg_phi<1.0].compute(), int(agg_phi_bins/2), retbins=True)\n",
    "res, phi_bins2 = pd.qcut(df_repart.agg_phi[df_repart.agg_phi>=1.0].compute(), int(agg_phi_bins/2), retbins=True)\n",
    "\n",
    "for i in range(int(agg_phi_bins/2)):\n",
    "    phi_bins2=np.insert(phi_bins2,0,0)\n",
    "    \n",
    "all_phi_bins = np.concatenate([phi_bins1,phi_bins2[10:]])\n",
    "all_r_bins = np.empty((agg_phi_bins,agg_r_bins+1))\n",
    "for i in range(agg_phi_bins):\n",
    "\n",
    "    if i < int(agg_phi_bins/2): #skip the empty bin range surrounding phi=1.0\n",
    "        phi_bins = phi_bins1\n",
    "    else:\n",
    "        phi_bins = phi_bins2\n",
    "    print(i, phi_bins[i], phi_bins[i+1])\n",
    "        \n",
    "    #return a df that only queries within an aspect ratio bin\n",
    "    df_phi = df_repart[(df_repart.agg_phi > phi_bins[i]) & (df_repart.agg_phi < phi_bins[i+1]) & \\\n",
    "                      (df_repart.ncrystals > 2)]  #to ensure at least 2 crystals within agg since ncrystals=1 not in db\n",
    "    #now break that aspect ratio bin into n equal r bins\n",
    "    res, r_bins = pd.qcut(df_phi.agg_r.compute(), agg_r_bins, retbins=True)\n",
    "    all_r_bins[i,:] = r_bins\n",
    "all_phi_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('instance_files/instance_db_aggagg_flat_even', 'rb')\n",
    "b = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for returning output as an array\n",
    "nclusters = 300\n",
    "rxs = np.zeros((20,20,nclusters))\n",
    "rys = np.zeros((20,20,nclusters))\n",
    "rzs = np.zeros((20,20,nclusters))\n",
    "phi2Ds = np.zeros((20,20,nclusters))\n",
    "cplxs = np.zeros((20,20,nclusters))\n",
    "dds = np.zeros((20,20,nclusters))\n",
    "cluster1_ncrystals = np.zeros((20,20,nclusters))\n",
    "cluster2_ncrystals = np.zeros((20,20,nclusters))\n",
    "       \n",
    "for phi in range(20):\n",
    "    for r in range(20):\n",
    "        rxs[phi, r, :] = b['rxs'][phi,r,:]\n",
    "        rys[phi, r, :] = b['rys'][phi,r,:]\n",
    "        rzs[phi, r, :] = b['rzs'][phi,r,:]\n",
    "        phi2Ds[phi, r, :] = b['phi2Ds'][phi,r,:]\n",
    "        cplxs[phi, r, :] = b['cplxs'][phi,r,:]\n",
    "        dds[phi, r, :] = b['dd'][phi,r,:]\n",
    "        cluster1_ncrystals[phi, r, :] = b['cluster1_ncrystals'][phi,r,:]\n",
    "        cluster2_ncrystals[phi, r, :] = b['cluster2_ncrystals'][phi,r,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for returning output as a long list\n",
    "#FLAT\n",
    "#a=z b=y c=x\n",
    "\n",
    "#dunnavan: a>= b >= c\n",
    "#in our case z >= y >= x\n",
    "\n",
    "nclusters = 300\n",
    "rxs_flat = np.zeros((20,20,nclusters))\n",
    "rys_flat = np.zeros((20,20,nclusters))\n",
    "rzs_flat = np.zeros((20,20,nclusters))\n",
    "phi2Ds_flat = np.zeros((20,20,nclusters))\n",
    "cplxs_flat = np.zeros((20,20,nclusters))\n",
    "dds_flat = np.zeros((20,20,nclusters))\n",
    "\n",
    "counter=0       \n",
    "for phi in range(20):\n",
    "    for r in range(20):\n",
    "        rxs_flat[phi, r, :] = np.array(bflat[counter][0])[:,0]\n",
    "        rys_flat[phi, r, :] = np.array(bflat[counter][0])[:,1]\n",
    "        rzs_flat[phi, r, :] = np.array(bflat[counter][0])[:,2]\n",
    "        phi2Ds_flat[phi, r, :] = bflat[counter][1]\n",
    "        cplxs_flat[phi, r, :] = bflat[counter][2]\n",
    "        dds_flat[phi, r, :] = bflat[counter][3]\n",
    "        counter+=1\n",
    "phiba_flat = rys_flat/rzs_flat\n",
    "phica_flat = rxs_flat/rzs_flat\n",
    "np.shape(phica_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAND\n",
    "nclusters = 300\n",
    "rxs_rand = np.zeros((20,20,nclusters))\n",
    "rys_rand = np.zeros((20,20,nclusters))\n",
    "rzs_rand = np.zeros((20,20,nclusters))\n",
    "phi2Ds_rand = np.zeros((20,20,nclusters))\n",
    "cplxs_rand = np.zeros((20,20,nclusters))\n",
    "dds_rand = np.zeros((20,20,nclusters))\n",
    "\n",
    "counter=0\n",
    "for phi in range(20):\n",
    "    for r in range(20):\n",
    "        rxs_rand[phi, r, :] = np.array(brand[counter][0])[:,0]\n",
    "        rys_rand[phi, r, :] = np.array(brand[counter][0])[:,1]\n",
    "        rzs_rand[phi, r, :] = np.array(brand[counter][0])[:,2]\n",
    "        phi2Ds_rand[phi, r, :] = brand[counter][1]\n",
    "        cplxs_rand[phi, r, :] = brand[counter][2]\n",
    "        dds_rand[phi, r, :] = brand[counter][3]\n",
    "        counter+=1\n",
    "phiba_rand = rys_rand/rzs_rand\n",
    "phica_rand = rxs_rand/rzs_rand\n",
    "np.shape(phica_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IceClusterBatch():\n",
    "    \"\"\"A collection of IceCluster objects.\"\"\"\n",
    "    \n",
    "    def __init__(self, nclusters, rxs, rys, rzs, phi2Ds, cplxs, dds, numaspectratios, numrs):\n",
    "\n",
    "        self.nclusters=nclusters\n",
    "        self.rxs = rxs\n",
    "        self.rys = rys\n",
    "        self.rzs = rzs\n",
    "        self.phi2Ds = phi2Ds\n",
    "        self.cplxs = cplxs\n",
    "        self.dds = dds\n",
    "        self.numaspectratios = numaspectratios\n",
    "        self.numrs = numrs\n",
    "\n",
    "\n",
    "    def calculate_error(self, data, ch):\n",
    "        mean = np.mean(data)\n",
    "        std = np.std(data)\n",
    "        shape = (mean/std)**2\n",
    "        scale = (std**2)/mean\n",
    "        shapech = mean/(self.numaspectratios*ch)\n",
    "\n",
    "        pos_error = mean + std\n",
    "        neg_error = mean - std\n",
    "\n",
    "        min_data = min(data)\n",
    "        max_data = max(data)\n",
    "\n",
    "        return(pos_error, neg_error, min_data, max_data, mean)        \n",
    "\n",
    "\n",
    "    def fit_distribution(self, data, normed = True, facecolor='navy', alpha=1.0,**kwargs):\n",
    "\n",
    "        \"\"\"Model data by finding best fit distribution to data\"\"\"\n",
    "        # Get histogram of original data\n",
    "\n",
    "        #fig = plt.figure(figsize=(5,7))\n",
    "        #ax = plt.subplot(131)\n",
    "\n",
    "        data = np.array(data)\n",
    "        data[np.isinf(data)] = min(data)\n",
    "        data[np.isnan(data)] = min(data)\n",
    "        if np.isinf(data).any():\n",
    "            print('inf True')\n",
    "        y, x = np.histogram(data, density=True)\n",
    "        #print('x hist',x)\n",
    "        xx = (x + np.roll(x, -1))[:-1] / 2.0\n",
    "\n",
    "        \n",
    "        params = st.gamma.fit(data)\n",
    "        gamma_params = params\n",
    "        arg = gamma_params[:-2]\n",
    "        #fig = plt.figure(figsize=(10,7))\n",
    "        #ax = fig.add_subplot(111)\n",
    "        #n, bins, patches = plt.hist(data, bins=bins, normed=True,\n",
    "        #                            color='navy',range=(min(data), max(data)),**kwargs)\n",
    "        #pdf = self.make_pdf(distribution, gamma_params)\n",
    "        pdf = st.gamma.pdf(xx, loc=gamma_params[-2], scale=gamma_params[-1], *arg)\n",
    "        indmax = np.argmax(pdf)  #FIRST index where the highest prob occurs\n",
    "        gammach_var = x[indmax] #characteristic of the distribution\n",
    "        #ax = plt.plot(xx, pdf, lw=5, color='darkorange')\n",
    "        #plt.show()\n",
    "\n",
    "        return gammach_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find characteristic of gamma distribution\n",
    "numaspectratios=len(rxs[:,0,0])\n",
    "numrs=len(rxs[0,:,0])\n",
    "batch = IceClusterBatch(nclusters, rxs, rys, rzs, phi2Ds, \\\n",
    "                        cplxs, dds, numaspectratios, numrs)\n",
    "\n",
    "rxs_ch = np.empty((numaspectratios, numrs), dtype=np.float64)\n",
    "rzs_ch = np.empty((numaspectratios, numrs), dtype=np.float64)\n",
    "rzs_mean = np.empty((numaspectratios, numrs), dtype=np.float64)\n",
    "dds_ch = np.empty((numaspectratios, numrs), dtype=np.float64)\n",
    "\n",
    "for i in range(numaspectratios):\n",
    "    for r in range(numrs):\n",
    "        for c, data in enumerate([rxs, rzs, dds]):\n",
    "            if c == 0:\n",
    "                rxs_ch[i,r] = batch.fit_distribution(data[i,r,:])\n",
    "            if c == 1:\n",
    "                rzs_ch[i,r] = batch.fit_distribution(data[i,r,:])\n",
    "                _,_,_,_,rzs_mean[i,r] = batch.calculate_error(data[i,r,:], rzs_ch[i,r])\n",
    "            if c == 2:\n",
    "                dds_ch[i,r] = batch.fit_distribution(data[i,r,:])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to file for output as array:\n",
    "with open(\"lookup_tables/minorax_flat_ch_evensplit.dat\",\"wb\") as file1:\n",
    "    with open(\"lookup_tables/majorax_flat_ch_evensplit.dat\",\"wb\") as file2:\n",
    "        with open(\"lookup_tables/majorax_flat_mean_evensplit.dat\",\"wb\") as file3:\n",
    "            with open(\"lookup_tables/dd_flat_ch_evensplit.dat\",\"wb\") as file4:\n",
    "                file1.write('Agg-Agg collection from the database for the flat orientation. \\n')\n",
    "                file1.write('Characteristic values taken from the peak of a fitted \\n'\\\n",
    "                            'gamma distribution from 300 aggregates.  10 even count agg aspect \\n'\\\n",
    "                            'ratio bins are produced from values 0.01 to the closest value to 1.0 \\n'\\\n",
    "                            'and the closest value to 1.0 to 100.0 \\n')\n",
    "                file2.write('Agg-Agg collection from the database for the flat orientation. \\n')\n",
    "                file2.write('Characteristic values taken from the peak of a fitted \\n'\\\n",
    "                            'gamma distribution from 300 aggregates.  10 even count agg aspect \\n'\\\n",
    "                            'ratio bins are produced from values 0.01 to the closest value to 1.0 \\n'\\\n",
    "                            'and the closest value to 1.0 to 100.0 \\n')\n",
    "                file3.write('Agg-Agg collection from the database for the flat orientation. \\n')\n",
    "                file3.write('Characteristic values taken from the peak of a fitted \\n'\\\n",
    "                            'gamma distribution from 300 aggregates.  10 even count agg aspect \\n'\\\n",
    "                            'ratio bins are produced from values 0.01 to the closest value to 1.0 \\n'\\\n",
    "                            'and the closest value to 1.0 to 100.0 \\n')\n",
    "                file4.write('Agg-Agg collection from the database for the flat orientation. \\n')\n",
    "                file4.write('Characteristic values taken from the peak of a fitted \\n'\\\n",
    "                            'gamma distribution from 300 aggregates.  10 even count agg aspect \\n'\\\n",
    "                            'ratio bins are produced from values 0.01 to the closest value to 1.0 \\n'\\\n",
    "                            'and the closest value to 1.0 to 100.0 \\n')\n",
    "                \n",
    "                            \n",
    "                for i in range(agg_phi_bins):\n",
    "\n",
    "                    if i < int(agg_phi_bins/2): #skip the empty bin range surrounding phi=1.0\n",
    "                        phi_bins = phi_bins1\n",
    "                    else:\n",
    "                        phi_bins = phi_bins2\n",
    "                    #print(i, phi_bins[i], phi_bins[i+1])\n",
    "\n",
    "                    for r in range(agg_r_bins):\n",
    "                        #print(i,r)\n",
    "                        #print(all_r_bins[i,r], all_r_bins[i,r+1])\n",
    "                        file1.write('%.3f, %.3f, %.2f, %.2f, %.2f \\n' %(phi_bins[i], phi_bins[i+1],\\\n",
    "                                                                        all_r_bins[i,r], all_r_bins[i,r+1], rxs_ch[i,r]))\n",
    "                        file2.write('%.3f, %.3f, %.2f, %.2f, %.2f \\n' %(phi_bins[i], phi_bins[i+1],\\\n",
    "                                                                        all_r_bins[i,r], all_r_bins[i,r+1], rzs_ch[i,r]))\n",
    "                        file3.write('%.3f, %.3f, %.2f, %.2f, %.2f \\n' %(phi_bins[i], phi_bins[i+1], \\\n",
    "                                                                        all_r_bins[i,r], all_r_bins[i,r+1], rzs_mean[i,r]))\n",
    "                        file4.write('%.3f, %.3f, %.2f, %.2f, %.4f \\n' %(phi_bins[i], phi_bins[i+1], \\\n",
    "                                                                        all_r_bins[i,r], all_r_bins[i,r+1], dds_ch[i,r]))\n",
    "\n",
    "file1.close()\n",
    "file2.close() \n",
    "file3.close()\n",
    "file4.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find characteristic of gamma distribution from output as list\n",
    "numaspectratios=np.shape(rxs_flat)[0]\n",
    "numrs=np.shape(rxs_flat)[1]\n",
    "batch = IceClusterBatch(nclusters, rxs_flat, rys_flat, rzs_flat, phi2Ds_flat, \\\n",
    "                        cplxs_flat, dds_flat, numaspectratios, numrs)\n",
    "\n",
    "rxs_flat_ch = np.empty((numaspectratios, numrs), dtype=np.float64)\n",
    "rzs_flat_ch = np.empty((numaspectratios, numrs), dtype=np.float64)\n",
    "rzs_flat_mean = np.empty((numaspectratios, numrs), dtype=np.float64)\n",
    "dds_flat_ch = np.empty((numaspectratios, numrs), dtype=np.float64)\n",
    "\n",
    "for i in range(numaspectratios):\n",
    "    for r in range(numrs):\n",
    "        for c, data in enumerate([rxs_flat, rzs_flat, dds_flat]):\n",
    "            if c == 0:\n",
    "                rxs_flat_ch[i,r] = batch.fit_distribution(data[i,r,:])\n",
    "            if c == 1:\n",
    "                rzs_flat_ch[i,r] = batch.fit_distribution(data[i,r,:])\n",
    "                _,_,_,_,rzs_flat_mean[i,r] = batch.calculate_error(data[i,r,:], rzs_flat_ch[i,r])\n",
    "            if c == 2:\n",
    "                dds_flat_ch[i,r] = batch.fit_distribution(data[i,r,:])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find characteristic of gamma distribution\n",
    "numaspectratios=np.shape(rxs_rand)[0]\n",
    "numrs=np.shape(rxs_rand)[1]\n",
    "batch = IceClusterBatch(nclusters, rxs_rand, rys_rand, rzs_rand, phi2Ds_rand, \\\n",
    "                        cplxs_rand, dds_rand, numaspectratios, numrs)\n",
    "\n",
    "rxs_rand_ch = np.empty((numaspectratios, numrs), dtype=np.float64)\n",
    "rzs_rand_ch = np.empty((numaspectratios, numrs), dtype=np.float64)\n",
    "rzs_rand_mean = np.empty((numaspectratios, numrs), dtype=np.float64)\n",
    "dds_rand_ch = np.empty((numaspectratios, numrs), dtype=np.float64)\n",
    "\n",
    "for i in range(numaspectratios):\n",
    "    for r in range(numrs):\n",
    "        for c, data in enumerate([rxs_rand, rzs_rand, dds_rand]):\n",
    "            if c == 0:\n",
    "                rxs_rand_ch[i,r] = batch.fit_distribution(data[i,r,:])\n",
    "            if c == 1:\n",
    "                rzs_rand_ch[i,r] = batch.fit_distribution(data[i,r,:])\n",
    "                _,_,_,_,rzs_rand_mean[i,r] = batch.calculate_error(data[i,r,:], rzs_rand_ch[i,r])\n",
    "            if c == 2:\n",
    "                dds_rand_ch[i,r] = batch.fit_distribution(data[i,r,:])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to file:\n",
    "#FLAT\n",
    "%store -r phi_bins_flat\n",
    "%store -r all_r_bins_flat\n",
    "\n",
    "with open(\"lookup_tables/minorax_flat_ch.dat\",\"w+\") as file1:\n",
    "    with open(\"lookup_tables/majorax_flat_ch.dat\",\"w+\") as file2:\n",
    "        with open(\"lookup_tables/majorax_flat_mean.dat\",\"w+\") as file3:\n",
    "            with open(\"lookup_tables/dd_flat_ch.dat\",\"w+\") as file4:\n",
    "\n",
    "                    for phi in range(len(phi_bins_flat)-1):\n",
    "                        for r in range(len(all_r_bins_flat[phi,:])-1):\n",
    "                            file1.write('%.3f, %.3f, %.2f, %.2f, %.2f \\n' %(phi_bins_flat[phi], phi_bins_flat[phi+1],\\\n",
    "                                                                            all_r_bins_flat[phi,r], all_r_bins_flat[phi,r+1], rxs_flat_ch[phi,r]))\n",
    "                            file2.write('%.3f, %.3f, %.2f, %.2f, %.2f \\n' %(phi_bins_flat[phi], phi_bins_flat[phi+1],\\\n",
    "                                                                            all_r_bins_flat[phi,r], all_r_bins_flat[phi,r+1], rzs_flat_ch[phi,r]))\n",
    "                            file3.write('%.3f, %.3f, %.2f, %.2f, %.2f \\n' %(phi_bins_flat[phi], phi_bins_flat[phi+1], \\\n",
    "                                                                            all_r_bins_flat[phi,r], all_r_bins_flat[phi,r+1], rzs_flat_mean[phi,r]))\n",
    "                            file4.write('%.3f, %.3f, %.2f, %.2f, %.4f \\n' %(phi_bins_flat[phi], phi_bins_flat[phi+1], \\\n",
    "                                                                            all_r_bins_flat[phi,r], all_r_bins_flat[phi,r+1], dds_flat_ch[phi,r]))\n",
    "\n",
    "file1.close()\n",
    "file2.close() \n",
    "file3.close()\n",
    "file4.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to file:\n",
    "#RAND\n",
    "%store -r phi_bins_rand\n",
    "%store -r all_r_bins_rand\n",
    "\n",
    "with open(\"lookup_tables/minorax_rand_ch.dat\",\"w+\") as file1:\n",
    "    with open(\"lookup_tables/majorax_rand_ch.dat\",\"w+\") as file2:\n",
    "        with open(\"lookup_tables/majorax_rand_mean.dat\",\"w+\") as file3:\n",
    "            with open(\"lookup_tables/dd_rand_ch.dat\",\"w+\") as file4:\n",
    "\n",
    "                    for phi in range(len(phi_bins_rand)-1):\n",
    "                        for r in range(len(all_r_bins_rand[phi,:])-1):\n",
    "                            file1.write('%.3f, %.3f, %.2f, %.2f, %.2f \\n' %(phi_bins_rand[phi], phi_bins_rand[phi+1],\\\n",
    "                                                                            all_r_bins_rand[phi,r], all_r_bins_rand[phi,r+1], rxs_rand_ch[phi,r]))\n",
    "                            file2.write('%.3f, %.3f, %.2f, %.2f, %.2f \\n' %(phi_bins_rand[phi], phi_bins_rand[phi+1],\\\n",
    "                                                                            all_r_bins_rand[phi,r], all_r_bins_rand[phi,r+1], rzs_rand_ch[phi,r]))\n",
    "                            file3.write('%.3f, %.3f, %.2f, %.2f, %.2f \\n' %(phi_bins_rand[phi], phi_bins_rand[phi+1], \\\n",
    "                                                                            all_r_bins_rand[phi,r], all_r_bins_rand[phi,r+1], rzs_rand_mean[phi,r]))\n",
    "                            file4.write('%.3f, %.3f, %.2f, %.2f, %.4f \\n' %(phi_bins_rand[phi], phi_bins_rand[phi+1], \\\n",
    "                                                                            all_r_bins_rand[phi,r], all_r_bins_rand[phi,r+1], dds_rand_ch[phi,r]))\n",
    "\n",
    "file1.close()\n",
    "file2.close() \n",
    "file3.close()\n",
    "file4.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
