{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reloads the lab.py and crystals.py modules to update any changes (after saving)\n",
    "#If a new method or object is created, autoreload doesn't work and the \n",
    "#kernel needs to be closed and halted after saving and making a 'checkpoint'\n",
    "#in this notebook\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sqlite3 import Connection as SQLite3Connection\n",
    "from sqlalchemy import create_engine, event, select\n",
    "from sqlalchemy.engine import Engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import base\n",
    "from ipas import lab_ice_agg_SQL as lab\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client\n",
    "from dask import delayed\n",
    "import cloudpickle as pickle\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import time\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LogNorm\n",
    "import scipy.stats as stats \n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14 days batch \n",
    "#5 days kratos\n",
    "#cluster = SLURMCluster(\n",
    "#    queue='kratos',\n",
    "#    walltime='04-23:00:00',\n",
    "#    cores=1,\n",
    "##    memory='4096MiB', #1 GiB = 1,024 MiB\n",
    "#    processes=1)\n",
    "\n",
    "cluster = SLURMCluster(\n",
    "    queue='batch',\n",
    "    walltime='02-23:00:00',\n",
    "    cores=1,\n",
    "    memory='7168MiB', #1 GiB = 1,024 MiB\n",
    "    processes=1)\n",
    "\n",
    "\n",
    "cluster.scale(1)\n",
    "#2 nodes 128 GiB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phioarr=np.logspace(-2, 2, num=20, dtype=None)#just columns (0,2); plates (-2,0)\n",
    "#phioarr = phioarr[1:]\n",
    "lenphio = len(phioarr)\n",
    "\n",
    "reqarr = [6,7,8,9]\n",
    "numaspectratios=len(phioarr)\n",
    "ch_dist='gamma'         #anything other than gamma uses the characteristic from the best distribution pdf (lowest SSE)\n",
    "nclusters = 300        #changes how many aggregates per aspect ratio to consider\n",
    "ncrystals = 50       #number of monomers per aggregate 1\n",
    "minor = 'depth'        #'minorxy' from fit ellipse or 'depth' to mimic IPAS in IDL\n",
    "rand_orient = True    #randomly orient the seed crystal and new crystal: uses first random orientation\n",
    "save_plots = False     #saves all histograms to path with # of aggs and minor/depth folder\n",
    "file_ext = 'eps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    '''\n",
    "    engine = create_engine('sqlite:///IPAS_1_lastmono.sqlite')\n",
    "    event.listen(engine, 'connect', _set_sqlite_pragma)\n",
    "    \n",
    "    base.Base.metadata.create_all(engine, checkfirst=True)\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "\n",
    "    for phio in phioarr:\n",
    "        for r in reqarr:\n",
    "            b1 = lab.collect_clusters(phio, r, session, nclusters=nclusters,\n",
    "                                ncrystals=ncrystals, rand_orient=rand_orient)\n",
    "    \n",
    "    '''\n",
    "    notebook=1\n",
    "    for r in reqarr:\n",
    "        #b3 = []\n",
    "        print('r = ',r)\n",
    "        count = 1\n",
    "        pool = Pool(processes=20) #pools are reusable\n",
    "        parallel_clus=partial(lab.collect_clusters, notebook=notebook, r=r, nclusters=nclusters,\\\n",
    "                                ncrystals=ncrystals, \\\n",
    "                                rand_orient=rand_orient)\n",
    "\n",
    "        start = time.time()\n",
    "        output = pool.imap_unordered(parallel_clus, phioarr)\n",
    "        for done in output:\n",
    "            print(\"after %3.1fsec: count:%s\"%(time.time()-start, count))\n",
    "            count +=1\n",
    "\n",
    "#         for res in output:\n",
    "#             print(\"(after %3.1fsec)  mono phi:%.3f  count:%s\"%(time.time()-start, res[0].mono_phi, count))\n",
    "#             count += 1\n",
    "        print('closing')\n",
    "        pool.close()\n",
    "        print('joining')\n",
    "        pool.join()\n",
    "        print('new r')\n",
    "    '''\n",
    "    \n",
    "    output = []\n",
    "    for r in reqarr:\n",
    "        for phio in phioarr:\n",
    "    \n",
    "            print('eq. vol rad', r, phio)\n",
    "\n",
    "            output.append(delayed(lab.collect_clusters)(phio, r, nclusters=nclusters,\n",
    "                                                        ncrystals=ncrystals, \n",
    "                                                        rand_orient=rand_orient))\n",
    "            \n",
    "    print(output)\n",
    "    #print('computing...')\n",
    "    b1 = client.compute(output, scheduler='distributed') \n",
    "\n",
    "    print('-------------gathering-----------')\n",
    "    b1 = client.gather(b1)\n",
    "    print('done gathering')\n",
    "    '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    %time main() \n",
    "     \n",
    "#     filename = 'instance_3radii_iceagg_allrand_50xtalstot_20phi_rall_300agg_1_lastmono'\n",
    "#     filehandler = open(filename, 'wb')\n",
    "#     %time pickle.dump(b1, filehandler)\n",
    "#     filehandler.close()\n",
    "#     print('finished, creating engine 1!')\n",
    "    \n",
    "#     engine = create_engine('sqlite:///IPAS_1_lastmono.sqlite')\n",
    "#     event.listen(engine, 'connect', _set_sqlite_pragma)\n",
    "    \n",
    "#     base.Base.metadata.create_all(engine, checkfirst=True)\n",
    "#     Session = sessionmaker(bind=engine)\n",
    "#     session = Session()\n",
    "    \n",
    "#     try:\n",
    "#         for obj in b1:\n",
    "#             session.add_all(obj)  # crystal id has been appended into cluster relationship\n",
    "#             session.commit()\n",
    "\n",
    "#     except:\n",
    "#         print('in except')\n",
    "#         raise\n",
    "\n",
    "      \n",
    "#     print('DONE!!!!!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'instance_3radii_iceagg_allrand_50xtalstot_20phi_rall_300agg_1_lastmono'\n",
    "filehandler = open(filename, 'wb')\n",
    "%time pickle.dump(b1, filehandler)\n",
    "filehandler.close()\n",
    "print('finished, creating engine 1!')\n",
    "\n",
    "engine = create_engine('sqlite:///IPAS_1_lastmono.sqlite')\n",
    "event.listen(engine, 'connect', _set_sqlite_pragma)\n",
    "\n",
    "base.Base.metadata.create_all(engine, checkfirst=True)\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "try:\n",
    "    for obj in b1:\n",
    "        session.add_all(obj)  # crystal id has been appended into cluster relationship\n",
    "        session.commit()\n",
    "\n",
    "except:\n",
    "    print('in except')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///IPAS_1_lastmono.sqlite')\n",
    "event.listen(engine, 'connect', _set_sqlite_pragma)\n",
    "\n",
    "base.Base.metadata.create_all(engine, checkfirst=True)\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "print('AGGREGATE PROPERTIES ==============')\n",
    "\n",
    "query = session.query(ipas.IceCluster)#, crys.IceCrystal)#.filter(crys.IceCrystal.id == 10)\n",
    "#query=session.query(clus.IceCluster).filter(crystals = 1).all()\n",
    "for agg in query.all():\n",
    "    print(agg.id, agg.ncrystals, agg.agg_phi, agg.cplx, agg.crystal[0].points,  agg.crystal[0].phi, agg.crystal[0].r)\n",
    "\n",
    "print('MONOMER PROPERTIES ================')\n",
    "query = session.query(ipas.IceCrystal)\n",
    "for mono in query.all():\n",
    "    print(mono.id, mono.phi, mono.r, mono.rand_orient, mono.aggs.ncrystals, mono.aggs.agg_phi)\n",
    "\n",
    "# try:\n",
    "#     for r in b1:\n",
    "#         for obj in r:\n",
    "#             session.add_all(obj)  # crystal id has been appended into cluster relationship\n",
    "#             session.commit()\n",
    "\n",
    "# except:\n",
    "#     print('in except')\n",
    "#     raise\n",
    "\n",
    "# session.close()  \n",
    "# print('DONE!!!!!')\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
