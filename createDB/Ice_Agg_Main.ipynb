{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Aggregation Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Reloads the lab.py and crystals.py modules to update any changes (after saving)\n",
    "#If a new method or object is created, autoreload doesn't work and the \n",
    "#kernel needs to be closed and halted after saving and making a 'checkpoint'\n",
    "#in this notebook\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import ipas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sqlite3 import Connection as SQLite3Connection\n",
    "from sqlalchemy import create_engine, event, select\n",
    "from sqlalchemy.engine import Engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import base\n",
    "from ipas import lab_ice_agg_SQL as lab\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client\n",
    "from dask import delayed\n",
    "import cloudpickle as pickle\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    queue='kratos',\n",
    "    walltime='04-23:00:00',\n",
    "    cores=1,\n",
    "    memory='7168MiB', #1 GiB = 1,024 MiB\n",
    "    processes=1)\n",
    "\n",
    "\n",
    "cluster.scale(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "phioarr=np.logspace(-2, 2, num=20, dtype=None)#just columns (0,2); plates (-2,0)\n",
    "#phioarr = phioarr[1:]\n",
    "lenphio = len(phioarr)\n",
    "\n",
    "reqarr = [50,60,70,80]\n",
    "numaspectratios=len(phioarr)\n",
    "ch_dist='gamma'         #anything other than gamma uses the characteristic from the best distribution pdf (lowest SSE)\n",
    "nclusters = 300        #changes how many aggregates per aspect ratio to consider\n",
    "ncrystals = 50       #number of monomers per aggregate 1\n",
    "minor = 'depth'        #'minorxy' from fit ellipse or 'depth' to mimic IPAS in IDL\n",
    "rand_orient = True    #randomly orient the seed crystal and new crystal: uses first random orientation\n",
    "save_plots = False     #saves all histograms to path with # of aggs and minor/depth folder\n",
    "file_ext = 'eps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    " \n",
    "    '''\n",
    "    for phio in phioarr:\n",
    "        for r in reqarr:\n",
    "            b1 = lab.collect_clusters(phio, r, nclusters=nclusters,\n",
    "                                ncrystals=ncrystals, rand_orient=rand_orient)     \n",
    "   \n",
    "    output = []\n",
    "    for r in reqarr:\n",
    "        for phio in phioarr:\n",
    "    \n",
    "            print('eq. vol rad', r, phio)\n",
    "            output.append(delayed(lab.collect_clusters)(phio, r, nclusters=nclusters,\n",
    "                                                        ncrystals=ncrystals, rand_orient=rand_orient))\n",
    "    \n",
    "    print(output)\n",
    "    print('computing...')\n",
    "    b1 = client.compute(output) \n",
    "    b1 = client.gather(b1)\n",
    "    '''\n",
    "\n",
    "    notebook=3\n",
    "    print(notebook)\n",
    "    for r in reqarr:\n",
    "        #b3 = []\n",
    "        print('r = ',r)\n",
    "        count = 1\n",
    "\n",
    "        pool = Pool(processes=20) #pools are reusable\n",
    "        parallel_clus=partial(lab.collect_clusters, notebook=notebook, r=r, nclusters=nclusters,\\\n",
    "                                ncrystals=ncrystals, \\\n",
    "                                rand_orient=rand_orient)\n",
    "\n",
    "        start = time.time()\n",
    "        output = pool.imap_unordered(parallel_clus, phioarr)\n",
    "        for done in output:\n",
    "            print(\"after %3.1fsec: count:%s\"%(time.time()-start, count))\n",
    "            count +=1\n",
    "\n",
    "#         for res in output:\n",
    "#             print(\"(after %3.1fsec)  mono phi:%.3f  count:%s\"%(time.time()-start, res[0].mono_phi, count))\n",
    "#             count += 1\n",
    "        print('closing')\n",
    "        pool.close()\n",
    "        print('joining')\n",
    "        pool.join()\n",
    "\n",
    "        \n",
    "        print('new r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    %time main() \n",
    "    \n",
    "#     filename = 'instance_3radii_iceagg_allrand_50xtalstot_20phi_rall_300agg_lastmono'\n",
    "#     filehandler = open(filename, 'wb')\n",
    "#     %time pickle.dump(b, filehandler)\n",
    "#     filehandler.close()\n",
    "#     print('finished, creating engine 1!')\n",
    "    \n",
    "#     engine = create_engine('sqlite:///IPAS_lastmono.sqlite')\n",
    "#     event.listen(engine, 'connect', _set_sqlite_pragma)\n",
    "#     base.Base.metadata.create_all(engine, checkfirst=True)\n",
    "#     Session = sessionmaker(bind=engine)\n",
    "#     session = Session()\n",
    "    \n",
    "#     try:\n",
    "#         for r in b:\n",
    "#             for obj in r:\n",
    "#                 session.add_all(obj)  # crystal id has been appended into cluster relationship\n",
    "#                 session.commit()\n",
    "\n",
    "#     except:\n",
    "#         print('in except')\n",
    "#         raise\n",
    "#     session.close() \n",
    "#     print('DONE!')\n",
    "    \n",
    "    #packed = msgpack.writeResult('msgpack_test', b1)\n",
    "    #msgpack.unpackb(packed, encoding='utf-8')\n",
    "    \n",
    "    #filename = 'instance_3radii_iceagg_allrand_100xtalstot_20phi_r10_1000agg'\n",
    "    #filehandler = open(filename, 'wb')\n",
    "    #%time pickle.dump(b1, filehandler)\n",
    "    #filehandler.close()\n",
    "    #print('finished!')\n",
    "    \n",
    "    #CHANGE LOOKUP TABLE FILES TO HAVE RANGE OF PHI AND R\n",
    "    #Kratos = 28*4nodes = 112 -> 28 req so 4 aspect ratios at a time\n",
    "    #would take 5 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_engines(eng_name):\n",
    "    engine=create_engine(eng_name)\n",
    "    db = 'SELECT * FROM aggregates'\n",
    "    df = pd.read_sql(db, con=engine)\n",
    "    return df\n",
    "\n",
    "# databases = ['sqlite:///IPAS.sqlite', 'sqlite:///IPAS_1.sqlite', 'sqlite:///IPAS_2.sqlite',\\\n",
    "#             'sqlite:///IPAS_3.sqlite', 'sqlite:///IPAS_4.sqlite', 'sqlite:///IPAS_5.sqlite']\n",
    "\n",
    "databases = ['sqlite:///IPAS.sqlite', 'sqlite:///IPAS_1.sqlite']\n",
    "\n",
    "pool = Pool(processes=2)\n",
    "df_all = pool.map(create_engines, databases)\n",
    "pool.close()\n",
    "\n",
    "# engine = create_engine('sqlite:///IPAS.sqlite')\n",
    "# engine1 = create_engine('sqlite:///IPAS_1.sqlite')\n",
    "# engine2 = create_engine('sqlite:///IPAS_2.sqlite')\n",
    "# engine3 = create_engine('sqlite:///IPAS_3.sqlite')\n",
    "# engine4 = create_engine('sqlite:///IPAS_4.sqlite')\n",
    "# engine5 = create_engine('sqlite:///IPAS_5.sqlite')\n",
    "\n",
    "# db = 'SELECT * FROM aggregates'\n",
    "# df = pd.read_sql(db, con=engine)\n",
    "# df1 = pd.read_sql(db, con=engine1)\n",
    "# df2 = pd.read_sql(db, con=engine2)\n",
    "# df3 = pd.read_sql(db, con=engine3)\n",
    "# df4 = pd.read_sql(db, con=engine4)\n",
    "# df5 = pd.read_sql(db, con=engine5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time df = dd.read_sql_table('aggregates', 'sqlite:///IPAS.sqlite',\\\n",
    "                       npartitions=10, index_col='id').persist()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time df_1 = dd.read_sql_table('aggregates', 'sqlite:///IPAS_1.sqlite',\\\n",
    "                       npartitions=28, index_col='id').persist()\n",
    "progress(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time df_2 = dd.read_sql_table('aggregates', 'sqlite:///IPAS_2.sqlite',\\\n",
    "                       npartitions=28, index_col='id')\n",
    "df_2.persist() \n",
    "progress(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%time df_3 = dd.read_sql_table('aggregates', 'sqlite:///IPAS_3.sqlite',\\\n",
    "                       npartitions=28, index_col='id')\n",
    "df_3.persist() \n",
    "progress(df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.persist() \n",
    "progress(df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time df_4 = dd.read_sql_table('aggregates', 'sqlite:///IPAS_4.sqlite',\\\n",
    "                       npartitions=28, index_col='id')\n",
    "df_4.persist() \n",
    "progress(df_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time df_5 = dd.read_sql_table('aggregates', 'sqlite:///IPAS_5.sqlite',\\\n",
    "                       npartitions=28, index_col='id')\n",
    "df_5.persist() \n",
    "progress(df_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# engine = create_engine('sqlite:///IPAS_1.sqlite')\n",
    "# base.Base.metadata.create_all(engine, checkfirst=True)\n",
    "# Session = sessionmaker(bind=engine)\n",
    "# session = Session()\n",
    "\n",
    "engine = create_engine('sqlite:///IPAS_bkup.sqlite', echo=True)\n",
    "engine.execute(\"attach database 'IPAS_1.sqlite' as d1;\")\n",
    "engine.execute(\"attach database 'IPAS_2.sqlite' as d2;\")\n",
    "engine.execute(\"attach database 'IPAS_3.sqlite' as d3;\")\n",
    "engine.execute(\"attach database 'IPAS_4.sqlite' as d4;\")\n",
    "engine.execute(\"attach database 'IPAS_5.sqlite' as d5;\")\n",
    "  \n",
    "Session = sessionmaker(bind=engine)\n",
    "\n",
    "\n",
    "session = Session()\n",
    "inspector = Inspector.from_engine(engine)\n",
    "print(inspector.get_table_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engines = []\n",
    "sessions = []\n",
    "databases=[IPAS.sqlite, IPAS_1.sqlite, IPAS_2.sqlite, IPAS_3.sqlite, IPAS_4.sqlite, IPAS_5.sqlite]\n",
    "for dbconninfo in databases:\n",
    "    engine = create_engine(dbconninfo)\n",
    "    engines.append(engine)\n",
    "    sessions.append(sessionmaker(bind=engine)())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print('AGGREGATE PROPERTIES ==============')\n",
    "\n",
    "#print(session.query(ipas.IceCluster).count())#, crys.IceCrystal)#.filter(crys.IceCrystal.id == 10)\n",
    "\n",
    "#print(session.query(ipas.IceCluster).filter(ipas.IceCrystal.r == 7).count())\n",
    "#query = session.query(ipas.IceCluster).filter(ipas.IceCrystal.r == 10).limit(10)\n",
    "\n",
    "for value in session.query(ipas.IceCrystal.r).distinct():\n",
    "    print(value)\n",
    "\n",
    "#for agg in query:\n",
    "#    print(agg.id, agg.ncrystals, agg.agg_phi, agg.cplx, agg.crystal[0].id,  agg.crystal[0].phi, agg.crystal[0].r)\n",
    "\n",
    "#print('MONOMER PROPERTIES ================')\n",
    "#query = session.query(ipas.IceCrystal).all()[0:5]\n",
    "#for mono in query:\n",
    "#    print(mono.id, mono.phi, mono.r, mono.rand_orient, mono.aggs.ncrystals, mono.aggs.agg_phi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(b1.rxs.shape)\n",
    "print(np.max(b1.rxs))\n",
    "print(np.max(b1.rys))\n",
    "print(np.max(b1.rzs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#a=x b=y c=z\n",
    "\n",
    "#dunnavan: a>= b >= c\n",
    "#in our case z > y > x\n",
    "phiba = b1.rxs/b1.rzs\n",
    "phica = b1.rys/b1.rzs\n",
    "#H, xedges, yedges = np.histogram2d(phica[10,:,2],phiba[10,:,2], normed=True)\n",
    "#plt.imshow(H)\n",
    "ax = sns.jointplot(x=phiba[1,:,2], y=phica[1,:,2], kind='hex')\n",
    "ax = sns.jointplot(x=phiba[1,:,2], y=phica[1,:,2], kind='kde')\n",
    "ax = sns.jointplot(x=phiba[19,:,2], y=phica[19,:,2], kind='hex', color='r')\n",
    "ax = sns.jointplot(x=phiba[19,:,2], y=phica[19,:,2], kind='kde', color='r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(phiba[10,:,2], bins='auto', color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "n, bins, patches = plt.hist(phica[10,:,2], bins='auto', color='r',\n",
    "                            alpha=0.7, rwidth=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#axes rand plates\n",
    "n, bins, patches = plt.hist(b1.rxs[1,:,2], bins='auto', color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "n, bins, patches = plt.hist(b1.rys[1,:,2], bins='auto', color='r',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "n, bins, patches = plt.hist(b1.rzs[1,:,2], bins='auto', color='g',\n",
    "                            alpha=0.7, rwidth=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#axes rand columns \n",
    "n, bins, patches = plt.hist(b1.rxs[19,:,2], bins='auto', color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "n, bins, patches = plt.hist(b1.rys[19,:,2], bins='auto', color='r',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "n, bins, patches = plt.hist(b1.rzs[19,:,2], bins='auto', color='g',\n",
    "                            alpha=0.7, rwidth=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(b1.rxs[1,:,19], bins='auto', color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "n, bins, patches = plt.hist(b1.rys[1,:,19], bins='auto', color='r',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "n, bins, patches = plt.hist(b1.rzs[1,:,19], bins='auto', color='g',\n",
    "                            alpha=0.7, rwidth=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "file = open('instance_3radii_iceagg_allflat_40xtalstot_20phi_r10', 'rb')\n",
    "b1 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "b5.ch_req_shape = b5.ch_req.reshape(28, 20, 40)[:,:,:-1]\n",
    "b5.ch_majorax_shape = b5.ch_majorax.reshape(28, 20, 40)[:,:,:-1]\n",
    "b5.ch_minorax_shape = b5.ch_minorax.reshape(28, 20, 40)[:,:,:-1]\n",
    "b5.chphi_shape = b5.chphi.reshape(28, 20, 40)[:,:,:-1]\n",
    "b5.ch_dd_shape = b5.ch_dd.reshape(28, 20, 40)[:,:,:-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "phioarr=np.logspace(-2, 2, num=20, dtype=None)#just columns (0,2); plates (-2,0)\n",
    "#phioarr = phioarr[1:]\n",
    "reqarr = [1,2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100,200,300,400,500,600,700,800,900,1000]\n",
    "ncrystals=39\n",
    "\n",
    "f1 = open('find_N_lookup_iceagg_flat_rall.dat',\"w\")\n",
    "f2 = open('major_axis_lookup_iceagg_flat_rall.dat',\"w\")\n",
    "f3 = open('minor_axis_lookup_iceagg_flat_rall.dat',\"w\")\n",
    "f4 = open('dd_lookup_iceagg_flat_rall.dat',\"w\")\n",
    "\n",
    "for i in range(len(reqarr)):\n",
    "    for j in range(len(phioarr)):   \n",
    "        for N in range((ncrystals)):\n",
    "            #f1.write('%.3f\\t %.1f\\t %.4f\\t %10.4f\\t\\n'%(b1.phioarr[j], reqarr[i], b1.chphi[N], b1.ch_req[N]))\n",
    "            f1.write('{:8.4f} {:8.2f} {:8.4f} {:10.2f}\\n'.format(b5.phioarr[j], reqarr[i], b5.chphi_shape[i,j,N], b5.ch_req_shape[i,j,N]))\n",
    "            #f2.write('%.3f\\t %.1f\\t %.4f\\t\\n'%(b1.phioarr[j], reqarr[i], b1.ch_majorax[N]))\n",
    "            f2.write('{:8.4f} {:8.2f} {:10.2f}\\n'.format(b5.phioarr[j], reqarr[i], b5.ch_majorax_shape[i,j,N]))\n",
    "            #print(b1.phioarr[j], reqarr[i], b1.ch_majorax[N])\n",
    "           \n",
    "            #minor_axis\n",
    "            f3.write('{:8.4f} {:8.2f} {:8.4f}\\n'.format(b5.phioarr[j], reqarr[i], b5.ch_minorax_shape[i,j,N]))\n",
    "            #f3.write('%.3f\\t %.1f\\t %.4f\\t\\n'%(b1.phioarr[j], reqarr[i], b1.ch_minorax[N]))\n",
    "            #density change\n",
    "            f4.write(\"{:8.4f} {:8.2f} {:8.4f}\\n\".format(b5.phioarr[j], reqarr[i], b5.ch_dd_shape[i,j,N]))\n",
    "            #f4.write('%5.3f\\t %5.1f\\t %.5f\\t\\n'%(b1.phioarr[j], reqarr[i], b1.ch_dd[N]))\n",
    "            \n",
    "f1.close()\n",
    "f2.close()\n",
    "f3.close()\n",
    "f4.close()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
