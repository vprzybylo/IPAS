{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import dask\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dask import dataframe as dd\n",
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "\n",
    "import ipas.collection_no_db.m_D_relationship as collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_client(num_workers):\n",
    "    \"\"\"start dask client for parallelization\"\"\"\n",
    "    cluster = SLURMCluster(\n",
    "        queue=\"kratos\",\n",
    "        walltime=\"04-23:00:00\",\n",
    "        cores=1,\n",
    "        memory=\"10000MiB\",  # 1 GiB = 1,024 MiB\n",
    "        processes=1,\n",
    "    )\n",
    "\n",
    "    # cluster.adapt(minimum=3, maximum=20)\n",
    "    cluster.scale(num_workers)\n",
    "    client = Client(cluster)\n",
    "    print(\"dashboard link: \", cluster.dashboard_link)\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(filename, agg_as, agg_bs, agg_cs, Aps, Acs, Vps, Ves, Dmaxs):\n",
    "    \"\"\"write results to file\"\"\"\n",
    "    results = {\n",
    "        \"agg_as\": agg_as,\n",
    "        \"agg_bs\": agg_bs,\n",
    "        \"agg_cs\": agg_cs,\n",
    "        \"Aps\": Aps,\n",
    "        \"Acs\": Acs,\n",
    "        \"Vps\": Vps,\n",
    "        \"Ves\": Ves,\n",
    "        \"Dmaxs\": Dmaxs,\n",
    "    }\n",
    "    print(\"saving results to \", filename)\n",
    "    filehandler = open(filename, \"wb\")\n",
    "    pickle.dump(results, filehandler)\n",
    "    filehandler.close()\n",
    "    print(\"done writing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute(\n",
    "    phioarr,\n",
    "    reqarr,\n",
    "    nclusters,\n",
    "    ncrystals,\n",
    "    rand_orient,\n",
    "    use_dask=False,\n",
    "    num_workers=2,\n",
    "    plot=False,\n",
    "):\n",
    "    agg_as = np.empty((len(phioarr), len(reqarr), nclusters, ncrystals - 1))\n",
    "    agg_bs = np.empty((len(phioarr), len(reqarr), nclusters, ncrystals - 1))\n",
    "    agg_cs = np.empty((len(phioarr), len(reqarr), nclusters, ncrystals - 1))\n",
    "    Aps = np.empty((len(phioarr), len(reqarr), nclusters, ncrystals - 1))\n",
    "    Acs = np.empty((len(phioarr), len(reqarr), nclusters, ncrystals - 1))\n",
    "    Vps = np.empty((len(phioarr), len(reqarr), nclusters, ncrystals - 1))\n",
    "    Ves = np.empty((len(phioarr), len(reqarr), nclusters, ncrystals - 1))\n",
    "    Dmaxs = np.empty((len(phioarr), len(reqarr), nclusters, ncrystals - 1))\n",
    "\n",
    "    output = np.empty((len(phioarr), len(reqarr), nclusters), dtype=object)\n",
    "    for phi in range(len(phioarr)):\n",
    "        for r in range(len(reqarr)):\n",
    "            for n in range(nclusters):\n",
    "                if use_dask:\n",
    "                    output[phi, r, n] = dask.delayed(collect.collect_clusters_iceagg)(\n",
    "                        phioarr[phi], reqarr[r], ncrystals, rand_orient, plot=plot\n",
    "                    )\n",
    "                else:\n",
    "                    (\n",
    "                        agg_as[phi, r, n],\n",
    "                        agg_bs[phi, r, n],\n",
    "                        agg_cs[phi, r, n],\n",
    "                        Aps[phi, r, n],\n",
    "                        Acs[phi, r, n],\n",
    "                        Vps[phi, r, n],\n",
    "                        Ves[phi, r, n],\n",
    "                        Dmaxs[phi, r, n],\n",
    "                    ) = collect.collect_clusters_iceagg(\n",
    "                        phioarr[phi], reqarr[r], ncrystals, rand_orient, plot=plot\n",
    "                    )\n",
    "    if use_dask:\n",
    "        # start dask client\n",
    "        print('num workers', num_workers)\n",
    "        client = start_client(num_workers)\n",
    "        gather = client.compute([*output.tolist()])\n",
    "        gather = client.gather(gather)\n",
    "        gather = np.array(gather)\n",
    "        agg_as = gather[:, :, :, 0, :]  # phi, r, n, variable position, nm\n",
    "        agg_bs = gather[:, :, :, 1, :]\n",
    "        agg_cs = gather[:, :, :, 2, :]\n",
    "        Aps = gather[:, :, :, 3, :]\n",
    "        Acs = gather[:, :, :, 4, :]\n",
    "        Vps = gather[:, :, :, 5, :]\n",
    "        Ves = gather[:, :, :, 6, :]\n",
    "        Dmaxs = gather[:, :, :, 7, :]\n",
    "\n",
    "    return agg_as, agg_bs, agg_cs, Aps, Acs, Vps, Ves, Dmaxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # monomer aspect ratios (all the same in agg)\n",
    "    #phioarr=np.logspace(-2, 2, num=20, dtype=None)#just columns (0,2); plates (-2,0)\n",
    "    phioarr = [1.0]\n",
    "    # monomer radii \n",
    "    #reqarr = [1,2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100,200,300,400,500,600,700,800,900,1000]\n",
    "    reqarr = [10, 100, 1000]  # microns \n",
    "    # how many aggregates to produce\n",
    "    nclusters = 300\n",
    "    # number of monomers per aggregate\n",
    "    ncrystals = 100\n",
    "    # monomer orientation - random (True) or flat (False)\n",
    "    rand_orient = True\n",
    "\n",
    "    # save aggregate attributes to pickled file\n",
    "    save = True\n",
    "    #savename (relative path)\n",
    "    if save:\n",
    "        filename = '../../instance_files/mD_vT_vars'\n",
    "        \n",
    "    # parallelize IPAS using dask\n",
    "    use_dask = True\n",
    "    if use_dask:\n",
    "        num_workers = 10\n",
    "        agg_as, agg_bs, agg_cs, Aps, Acs, Vps, Ves, Dmaxs = compute(phioarr, reqarr, nclusters, ncrystals,\n",
    "                                                             rand_orient, use_dask=use_dask,\n",
    "                                                             num_workers=num_workers)\n",
    "    else:\n",
    "        # plot the aggregate?\n",
    "        plot = False\n",
    "        agg_as, agg_bs, agg_cs, Aps, Acs, Vps, Ves, Dmaxs = compute(phioarr, reqarr, nclusters,\n",
    "                                                             ncrystals, rand_orient, plot=plot)\n",
    "\n",
    "    if save:\n",
    "        write_file(filename, agg_as, agg_bs, agg_cs, Aps, Acs, Vps, Ves, Dmaxs)\n",
    "    print('DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num workers 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/network/rit/lab/sulialab/share/bin/miniconda3/envs/IPAS_v1.3.0/lib/python3.7/site-packages/distributed/node.py:155: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 42687 instead\n",
      "  http_address[\"port\"], self.http_server.port\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dashboard link:  http://169.226.65.78:42687/status\n",
      "saving results to  ../../instance_files/mD_vT_vars\n",
      "done writing!\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../../instance_files/mD_vT_vars'\n",
    "filehandler = open(filename, \"wb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/network/rit/lab/sulialab/share/IPAS/ipas/executables/collection_no_db\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "IPAS_v1.3.0",
   "language": "python",
   "name": "ipas_v1.3.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
