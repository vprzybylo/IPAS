{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipas.collection_no_db.iceice_collection as collect\n",
    "import numpy as np\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client\n",
    "import dask\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_client(num_workers):\n",
    "    cluster = SLURMCluster(\n",
    "    queue='kratos',\n",
    "    walltime='04-23:00:00',\n",
    "    cores=1,\n",
    "    memory='20000MiB', #1 GiB = 1,024 MiB\n",
    "    processes=1)\n",
    "\n",
    "    cluster.scale(num_workers)\n",
    "    client = Client(cluster)\n",
    "\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(filename, agg_as, agg_bs, agg_cs, phi2Ds, cplxs, dds):\n",
    "    '''write results to file'''\n",
    "    results = {'agg_as': agg_as, 'agg_bs':agg_bs, 'agg_cs':agg_cs,\n",
    "              'phi2Ds': phi2Ds,' cplxs': cplxs, 'dds': dds}\n",
    "    print('saving results to ', filename)\n",
    "    filehandler = open(filename, 'wb')\n",
    "    pickle.dump(results, filehandler)\n",
    "    filehandler.close()\n",
    "    print('done writing!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute(phioarr, reqarr, nclusters, ncrystals,\n",
    "            rand_orient, use_dask=False, num_workers=2,\n",
    "            plot=False):\n",
    "    '''\n",
    "    collect monomers and return aggregate attributes\n",
    "    '''\n",
    "    \n",
    "    agg_as = np.empty((len(phioarr),len(reqarr), nclusters, ncrystals-1))\n",
    "    agg_bs = np.empty((len(phioarr),len(reqarr), nclusters, ncrystals-1))\n",
    "    agg_cs = np.empty((len(phioarr),len(reqarr), nclusters, ncrystals-1))\n",
    "    phi2Ds = np.empty((len(phioarr),len(reqarr), nclusters, ncrystals-1))\n",
    "    cplxs = np.empty((len(phioarr),len(reqarr), nclusters, ncrystals-1))\n",
    "    dds = np.empty((len(phioarr),len(reqarr), nclusters, ncrystals-1))\n",
    "    \n",
    "    output = np.empty((len(phioarr),len(reqarr), nclusters),dtype=object)\n",
    "    for phi in range(len(phioarr)):\n",
    "        for r in range(len(reqarr)):\n",
    "            for n in range(nclusters):\n",
    "                if use_dask:\n",
    "                    output[phi,r,n] = dask.delayed(collect.collect_clusters_iceice)(phioarr[phi], reqarr[r],\n",
    "                                                                                   ncrystals, rand_orient, plot=plot)\n",
    "                else:\n",
    "                    agg_as[phi,r,n], agg_bs[phi,r,n], agg_cs[phi,r,n], phi2Ds[phi,r,n], cplxs[phi,r,n], dds[phi,r,n] = collect.collect_clusters_iceice(phioarr[phi], reqarr[r], ncrystals,\n",
    "                                                                                                    rand_orient, plot=plot)\n",
    "    \n",
    "    if use_dask:\n",
    "        #start dask client\n",
    "        client = start_client(num_workers)\n",
    "        gather = client.compute([*output.tolist()]) \n",
    "        gather = client.gather(gather)\n",
    "        gather = np.array(gather)\n",
    "        agg_as = gather[:,:,:,0,:]\n",
    "        agg_bs = gather[:,:,:,1,:]\n",
    "        agg_cs = gather[:,:,:,2,:]\n",
    "        phi2Ds = gather[:,:,:,3,:]\n",
    "        cplxs = gather[:,:,:,4,:] \n",
    "        dds = gather[:,:,:,5,:]\n",
    "    print('DONE!')\n",
    "    return agg_as, agg_bs, agg_cs, phi2Ds, cplxs, dds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # monomer aspect ratios (all the same in agg)\n",
    "    #phioarr=np.logspace(-2, 2, num=20, dtype=None)#just columns (0,2); plates (-2,0)\n",
    "    phioarr = [1.0, 0.25, 0.5, 1.0, 2.0, 4.0, 10.]\n",
    "    # monomer radii \n",
    "    #reqarr = [1,2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100,200,300,400,500,600,700,800,900,1000]\n",
    "    reqarr = [100,200]\n",
    "    # how many aggregates to produce\n",
    "    nclusters = 3\n",
    "    # number of monomers per aggregate\n",
    "    ncrystals = 5\n",
    "    # monomer orientation - random (True) or flat (False)\n",
    "    rand_orient = True\n",
    "\n",
    "    # save aggregate attributes to pickled file\n",
    "    save = True\n",
    "    #savename (relative path)\n",
    "    if save:\n",
    "        filename = '../../instance_files/test'\n",
    "        \n",
    "    # parallelize IPAS using dask\n",
    "    use_dask = True\n",
    "    if use_dask:\n",
    "        num_workers = 2\n",
    "        agg_as, agg_bs, agg_cs, phi2Ds, cplxs, dds = compute(phioarr, reqarr, nclusters, ncrystals,\n",
    "                                                             rand_orient, use_dask=use_dask,\n",
    "                                                             num_workers=num_workers)\n",
    "    else:\n",
    "        # plot the aggregate?\n",
    "        plot = False\n",
    "        agg_as, agg_bs, agg_cs, phi2Ds, cplxs, dds = compute(phioarr, reqarr, nclusters,\n",
    "                                                             ncrystals, rand_orient, plot=plot)\n",
    "\n",
    "    if save:\n",
    "        write_file(filename, agg_as, agg_bs, agg_cs, phi2Ds, cplxs, dds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/network/rit/lab/sulialab/share/bin/miniconda3/envs/IPAS_v1.3.0/lib/python3.7/site-packages/distributed/node.py:155: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 34597 instead\n",
      "  http_address[\"port\"], self.http_server.port\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "IPAS_v1.3.0",
   "language": "python",
   "name": "ipas_v1.3.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
