{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The heat extension is already loaded. To reload it, use:\n",
      "  %reload_ext heat\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import time\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client, progress\n",
    "import dask\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from shapely.ops import nearest_points\n",
    "from pyquaternion import Quaternion\n",
    "import copy as cp\n",
    "from scipy import spatial \n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import nearest_points\n",
    "import pandas as pd\n",
    "from dask import dataframe as dd\n",
    "import pickle\n",
    "import scipy.stats as st\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/network/rit/lab/sulialab/share/bin/miniconda3/envs/pangeo/lib/python3.6/site-packages/distributed/dashboard/core.py:72: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: 'tcp://169.226.65.164:38833' processes=0 threads=0, memory=0 B>\n"
     ]
    }
   ],
   "source": [
    "cluster = SLURMCluster(\n",
    "queue='kratos',\n",
    "walltime='04-23:00:00',\n",
    "cores=1,\n",
    "memory='20000MiB', #1 GiB = 1,024 MiB\n",
    "processes=1)\n",
    "\n",
    "cluster.scale(20)\n",
    "client = Client(cluster)\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    output = np.empty((len(phioarr),len(reqarr)),dtype=object)\n",
    "    for phi in range(len(phioarr)):\n",
    "        for r in range(len(reqarr)):\n",
    "            output[phi,r] = dask.delayed(ipas.collect_clusters)(phioarr[phi], reqarr[r], nclusters, ncrystals,rand_orient)\n",
    "            #ipas.collect_clusters(phioarr[phi], reqarr[r], nclusters, ncrystals,rand_orient)\n",
    "    #delayeds = client.compute(delayeds)\n",
    "    #output = client.gather(delayeds)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute():\n",
    "    agg_as = np.empty((len(phioarr),len(reqarr), nclusters))\n",
    "    agg_bs = np.empty((len(phioarr),len(reqarr), nclusters))\n",
    "    agg_cs = np.empty((len(phioarr),len(reqarr), nclusters))\n",
    "    phi2Ds = np.empty((len(phioarr),len(reqarr), nclusters))\n",
    "    cplxs = np.empty((len(phioarr),len(reqarr), nclusters))\n",
    "    dds = np.empty((len(phioarr),len(reqarr), nclusters))\n",
    "    major_ax_zs = np.empty((len(phioarr),len(reqarr), nclusters))\n",
    "    depths = np.empty((len(phioarr),len(reqarr), nclusters))\n",
    "    \n",
    "    gather = client.compute([*output.tolist()])  #only parallelizing agg r bins\n",
    "    gather = client.gather(gather)\n",
    "\n",
    "    gather = np.array(gather)\n",
    "    print(np.shape(gather))\n",
    "    agg_as = gather[:,:,0,:]\n",
    "    agg_bs = gather[:,:,1,:]\n",
    "    agg_cs = gather[:,:,2,:]\n",
    "    phi2Ds = gather[:,:,3,:]\n",
    "    cplxs = gather[:,:,4,:] \n",
    "    dds = gather[:,:,5,:]\n",
    "    major_ax_zs = gather[:,:,6,:]\n",
    "    depths = gather[:,:,7,:]\n",
    "    print('DONE!')\n",
    "    return agg_as, agg_bs, agg_cs, phi2Ds, cplxs, dds, major_ax_zs, depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 28, 8, 300)\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    phioarr=np.logspace(-2, 2, num=20, dtype=None)#just columns (0,2); plates (-2,0)\n",
    "    #phioarr = [ .01, 0.1, 1.0, 10, 100]\n",
    "    reqarr = [1,2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100,200,300,400,500,600,700,800,900,1000]\n",
    "    #reqarr = [10]\n",
    "    nclusters = 300         #changes how many aggregates per aspect ratio to consider\n",
    "    ncrystals = 2\n",
    "    rand_orient = False      #randomly orient the seed crystal and new crystal: uses first random orientation\n",
    "    \n",
    "    output = main()\n",
    "    agg_as, agg_bs, agg_cs, phi2Ds, cplxs, dds, major_ax_zs, depths = compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    }
   ],
   "source": [
    "results = {'agg_as': agg_as, 'agg_bs':agg_bs, 'agg_cs':agg_cs, 'phi2Ds':phi2Ds, \\\n",
    "           'cplxs':cplxs, 'dds':dds, 'major_ax_zs':major_ax_zs, 'depths':depths}\n",
    "filename = '../instance_files/instance_iceice_flat_rall_major_depth'\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(results, filehandler)\n",
    "filehandler.close()\n",
    "print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATA BACK IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../instance_files/instance_iceice_rand_rall_major_depth', 'rb')\n",
    "results = pickle.load(f)\n",
    "agg_as, agg_bs, agg_cs, phi2Ds, cplxs, dds, major_ax_zs, depths= \\\n",
    "                results['agg_as'], results['agg_bs'], results['agg_cs'], results['phi2Ds'], results['cplxs'], \\\n",
    "                results['dds'], results['major_ax_zs'], results['depths']\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(data, numaspectratios, ch):\n",
    "    data[np.isinf(data)] = min(data)\n",
    "    data[np.isnan(data)] = min(data)\n",
    "    data= data[(data<np.quantile(data, .99)) & (data>np.quantile(data, .01))]\n",
    "            \n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    shape = (mean/std)**2\n",
    "    scale = (std**2)/mean\n",
    "    shapech = mean/(numaspectratios*ch)\n",
    "\n",
    "    pos_error = mean + std\n",
    "    neg_error = mean - std\n",
    "\n",
    "    min_data = min(data)\n",
    "    max_data = max(data)\n",
    "\n",
    "    return(pos_error, neg_error, min_data, max_data, mean)   \n",
    "\n",
    "def mode_of_hist(data):\n",
    "    data[np.isinf(data)] = min(data)\n",
    "    data[np.isnan(data)] = min(data)\n",
    "    data= data[(data<np.quantile(data, .99)) & (data>np.quantile(data, .01))]\n",
    "    bins = (np.max(data) - np.min(data))/0.01\n",
    "    n, bins, patches = plt.hist(data, bins=int(bins), density=True,\n",
    "                                color='navy',range=(min(data), max(data)))\n",
    "    mode = bins[np.where(n == np.max(n))]\n",
    "\n",
    "    return mode[0]\n",
    "\n",
    "def fit_distribution(data, normed = True, facecolor='navy', alpha=1.0, axes=None, **kwargs):\n",
    "    data[np.isinf(data)] = min(data)\n",
    "    data[np.isnan(data)] = min(data)\n",
    "    data= data[(data<np.quantile(data, .99)) & (data>np.quantile(data, .01))]\n",
    "    # Get histogram of original data\n",
    "    y, x = np.histogram(data, density=True)\n",
    "    fit_alpha, fit_loc, fit_beta=st.gamma.fit(data)\n",
    "    pdf = st.gamma.pdf(x, a=fit_alpha, loc=fit_loc, scale=fit_beta)\n",
    "    indmax = np.argmax(pdf) #FIRST index where the highest prob occurs\n",
    "    gammach_ch = x[indmax] #characteristic of the distribution\n",
    "    \n",
    "    if axes is not None:\n",
    "        n, bins, patches = plt.hist(data, bins=70, density=True,\n",
    "                                color='navy',**kwargs)\n",
    "\n",
    "        ax = plt.plot(x, pdf, lw=5, color='darkorange')\n",
    "        plt.ylim(0,max(n))\n",
    "        plt.show()\n",
    "\n",
    "    return gammach_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#find characteristic of gamma distribution\n",
    "numaspectratios=len(agg_as[:,0,0])\n",
    "numrs=len(agg_bs[0,:,0])\n",
    "agg_cs_ch = np.empty((numaspectratios, numrs), dtype=np.float64) #major\n",
    "agg_as_ch = np.empty((numaspectratios, numrs), dtype=np.float64) #minor\n",
    "agg_as_mean = np.empty((numaspectratios, numrs), dtype=np.float64)\n",
    "dds_mode = np.empty((numaspectratios, numrs), dtype=np.float64)\n",
    "major_ax_zs_ch = np.empty((numaspectratios, numrs), dtype=np.float64)\n",
    "major_ax_zs_mean = np.empty((numaspectratios, numrs), dtype=np.float64)\n",
    "depths_ch = np.empty((numaspectratios, numrs), dtype=np.float64)\n",
    "\n",
    "fig = plt.figure(figsize=(5,7))\n",
    "ax = plt.subplot(131)\n",
    "\n",
    "for i in range(numaspectratios):\n",
    "    for r in range(numrs):\n",
    "        #print(i,r)\n",
    "        for c, data in enumerate([agg_cs, agg_as, dds, major_ax_zs, depths]):\n",
    "        \n",
    "            if c == 0:\n",
    "                agg_cs_ch[i,r] = fit_distribution(data[i,r,:])\n",
    "            if c == 1:\n",
    "                agg_as_ch[i,r] = fit_distribution(data[i,r,:])\n",
    "                pos_error, neg_error, min_data, max_data, agg_as_mean[i,r] = calculate_error(data[i,r,:], numaspectratios, agg_as_ch[i,r])\n",
    "            if c == 2:\n",
    "                #dds_ch[i,r] = fit_distribution(data[i,r,:])\n",
    "                dds_mode[i,r] = mode_of_hist(data[i,r])\n",
    "            if c == 3:\n",
    "                major_ax_zs_ch[i,r] = fit_distribution(data[i,r,:])\n",
    "                pos_error, neg_error, min_data, max_data, major_ax_zs_mean[i,r] = calculate_error(data[i,r,:], numaspectratios, major_ax_zs_ch[i,r])\n",
    "            if c == 4:\n",
    "                depths_ch[i,r] = fit_distribution(data[i,r,:])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to file for output as array:\n",
    "with open(\"../lookup_tables/ice_ice/newformat_minorax_ellipsoid_flat_ch.dat\",\"w\") as file1:\n",
    "    with open(\"../lookup_tables/ice_ice/newformat_majorax_ellipsoid_flat_ch.dat\",\"w\") as file2:\n",
    "        with open(\"../lookup_tables/ice_ice/newformat_majorax_ellipsoid_flat_mean.dat\",\"w\") as file3:\n",
    "            with open(\"../lookup_tables/ice_ice/newformat_dd_flat_mode.dat\",\"w\") as file4:\n",
    "                with open (\"../lookup_tables/ice_ice/newformat_majorax_ellipse_z_flat_ch.dat\",\"w\") as file5:\n",
    "                    with open (\"../lookup_tables/ice_ice/newformat_majorax_ellipse_z_flat_mean.dat\",\"w\") as file6:\n",
    "                        with open (\"../lookup_tables/ice_ice/newformat_depth_flat_ch.dat\",\"w\") as file7:\n",
    "                        \n",
    "                            file1.write('Ice-Ice collection for the flat orientation. \\n'\\\n",
    "                                        'Characteristic values taken from the peak of a fit \\n'\\\n",
    "                                        'gamma distribution from 300 aggregates. \\n'\\\n",
    "                                        'Minor axis taken as the smallest axis from the fit-ellipsoid \\n'\\\n",
    "                                        'Order: phi, r, value \\n')\n",
    "                            \n",
    "                            file2.write('Ice-Ice collection for the flat orientation. \\n'\n",
    "                                        'Characteristic values taken from the peak of a fit \\n'\\\n",
    "                                        'gamma distribution from 300 aggregates. \\n'\\\n",
    "                                        'Major axis taken as the largest axis from the fit-ellipsoid \\n'\n",
    "                                        'Order: phi, r, value \\n')\n",
    "                                \n",
    "                            file3.write('Ice-Ice collection for the flat orientation. \\n'\n",
    "                                        'Mean value taken from the average across 300 aggregates. \\n'\\\n",
    "                                        'Major axis taken as the largest axis from the fit-ellipsoid \\n'\n",
    "                                        'Order: phi, r, value \\n')\n",
    "                                \n",
    "                            file4.write('Ice-Ice collection for the flat orientation. \\n'\n",
    "                                        'Volume ratio of monomer (not 1.0) subtracted from volume ratio of agg (Vagg/Vellipse)\\n'\\\n",
    "                                        'then normalized by the volume ratio of monomer. \\n'\\\n",
    "                                        'Mode from 300 aggregates. \\n'\\\n",
    "                                        'Order: phi, r, value \\n')\n",
    "                                \n",
    "                            file5.write('Ice-Ice collection for the flat orientation. \\n'\\\n",
    "                                        'Characteristic values taken from the peak of a fit \\n'\\\n",
    "                                        'gamma distribution from 300 aggregates. \\n'\\\n",
    "                                        'Major axis taken from a fit-ellipse (2D) in the z-orientation. \\n'\n",
    "                                        'Order: phi, r, value \\n')\n",
    "                                \n",
    "                            file6.write('Ice-Ice collection for the flat orientation. \\n'\n",
    "                                        'Mean value taken from the average across 300 aggregates. \\n'\\\n",
    "                                        'Major axis taken from a fit-ellipse (2D) in the z-orientation. \\n'\n",
    "                                        'Order: phi, r, value \\n')\n",
    "                                \n",
    "                            file7.write('Ice-Ice collection for the flat orientation. \\n'\n",
    "                                        'Characteristic values taken from the peak of a fit \\n'\\\n",
    "                                        'gamma distribution from 300 aggregates. \\n'\\\n",
    "                                        'Depth measured as max z point - min z point. \\n'\n",
    "                                        'Order: phi, r, value \\n')\n",
    "\n",
    "                            for i in range(len(phioarr)):\n",
    "                                for r in range(len(reqarr)):\n",
    "                                    #print(i,r)\n",
    "                                    file1.write('%.3f %.2f %.2f \\n' %(phioarr[i], reqarr[r],  agg_cs_ch[i,r]))\n",
    "                                    file2.write('%.3f %.2f %.2f \\n' %(phioarr[i], reqarr[r],  agg_as_ch[i,r]))\n",
    "                                    file3.write('%.3f %.2f %.2f \\n' %(phioarr[i], reqarr[r],  agg_as_mean[i,r]))\n",
    "                                    file4.write('%.3f %.2f %.4f \\n' %(phioarr[i], reqarr[r],  dds_mode[i,r]))\n",
    "                                    file5.write('%.3f %.2f %.2f \\n' %(phioarr[i], reqarr[r],  major_ax_zs_ch[i,r]))\n",
    "                                    file6.write('%.3f %.2f %.2f \\n' %(phioarr[i], reqarr[r],  major_ax_zs_mean[i,r]))\n",
    "                                    file7.write('%.3f %.2f %.4f \\n' %(phioarr[i], reqarr[r],  depths_ch[i,r]))\n",
    "\n",
    "file1.close()\n",
    "file2.close() \n",
    "file3.close()\n",
    "file4.close()\n",
    "file5.close()\n",
    "file6.close()\n",
    "file7.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to file for output as array:\n",
    "with open(\"../lookup_tables/ice_ice/newformat_minorax_ellipsoid_rand_ch.dat\",\"w\") as file1:\n",
    "    with open(\"../lookup_tables/ice_ice/newformat_majorax_ellipsoid_rand_ch.dat\",\"w\") as file2:\n",
    "        with open(\"../lookup_tables/ice_ice/newformat_majorax_ellipsoid_rand_mean.dat\",\"w\") as file3:\n",
    "            with open(\"../lookup_tables/ice_ice/newformat_dd_rand_mode.dat\",\"w\") as file4:\n",
    "                with open (\"../lookup_tables/ice_ice/newformat_majorax_ellipse_z_rand_ch.dat\",\"w\") as file5:\n",
    "                    with open (\"../lookup_tables/ice_ice/newformat_majorax_ellipse_z_rand_mean.dat\",\"w\") as file6:\n",
    "                        with open (\"../lookup_tables/ice_ice/newformat_depth_rand_ch.dat\",\"w\") as file7:\n",
    "                        \n",
    "                            file1.write('Ice-Ice collection for the random orientation. \\n'\\\n",
    "                                        'Characteristic values taken from the peak of a fit \\n'\\\n",
    "                                        'gamma distribution from 300 aggregates. \\n'\\\n",
    "                                        'Minor axis taken as the smallest axis from the fit-ellipsoid \\n'\\\n",
    "                                        'Order: phi, r, value \\n')\n",
    "                            \n",
    "                            file2.write('Ice-Ice collection for the random orientation. \\n'\n",
    "                                        'Characteristic values taken from the peak of a fit \\n'\\\n",
    "                                        'gamma distribution from 300 aggregates. \\n'\\\n",
    "                                        'Major axis taken as the largest axis from the fit-ellipsoid \\n'\n",
    "                                        'Order: phi, r, value \\n')\n",
    "                                \n",
    "                            file3.write('Ice-Ice collection for the random orientation. \\n'\n",
    "                                        'Mean value taken from the average across 300 aggregates. \\n'\\\n",
    "                                        'Major axis taken as the largest axis from the fit-ellipsoid \\n'\n",
    "                                        'Order: phi, r, value \\n')\n",
    "                                \n",
    "                            file4.write('Ice-Ice collection for the random orientation. \\n'\n",
    "                                        'Volume ratio of monomer (not 1.0) subtracted from volume ratio of agg (Vagg/Vellipse)..\\n'\\\n",
    "                                        'then normalized by the volume ratio of monomer. \\n'\\\n",
    "                                        'Mode from 300 aggregates. \\n'\\\n",
    "                                        'Order: phi, r, value \\n')\n",
    "                                \n",
    "                            file5.write('Ice-Ice collection for the random orientation. \\n'\\\n",
    "                                        'Characteristic values taken from the peak of a fit \\n'\\\n",
    "                                        'gamma distribution from 300 aggregates. \\n'\\\n",
    "                                        'Major axis taken from a fit-ellipse (2D) in the z-orientation. \\n'\n",
    "                                        'Order: phi, r, value \\n')\n",
    "                                \n",
    "                            file6.write('Ice-Ice collection for the random orientation. \\n'\n",
    "                                        'Mean value taken from the average across 300 aggregates. \\n'\\\n",
    "                                        'Major axis taken from a fit-ellipse (2D) in the z-orientation. \\n'\n",
    "                                        'Order: phi, r, value \\n')\n",
    "                                \n",
    "                            file7.write('Ice-Ice collection for the random orientation. \\n'\n",
    "                                        'Characteristic values taken from the peak of a fit \\n'\\\n",
    "                                        'gamma distribution from 300 aggregates. \\n'\\\n",
    "                                        'Depth measured as max z point - min z point. \\n'\n",
    "                                        'Order: phi, r, value \\n')\n",
    "\n",
    "                            for i in range(len(phioarr)):\n",
    "                                for r in range(len(reqarr)):\n",
    "                                    #print(i,r)\n",
    "                                    file1.write('%.3f %.2f %.2f \\n' %(phioarr[i], reqarr[r],  agg_cs_ch[i,r]))\n",
    "                                    file2.write('%.3f %.2f %.2f \\n' %(phioarr[i], reqarr[r],  agg_as_ch[i,r]))\n",
    "                                    file3.write('%.3f %.2f %.2f \\n' %(phioarr[i], reqarr[r],  agg_as_mean[i,r]))\n",
    "                                    file4.write('%.3f %.2f %.4f \\n' %(phioarr[i], reqarr[r],  dds_mode[i,r]))\n",
    "                                    file5.write('%.3f %.2f %.2f \\n' %(phioarr[i], reqarr[r],  major_ax_zs_ch[i,r]))\n",
    "                                    file6.write('%.3f %.2f %.2f \\n' %(phioarr[i], reqarr[r],  major_ax_zs_mean[i,r]))\n",
    "                                    file7.write('%.3f %.2f %.4f \\n' %(phioarr[i], reqarr[r],  depths_ch[i,r]))\n",
    "\n",
    "file1.close()\n",
    "file2.close() \n",
    "file3.close()\n",
    "file4.close()\n",
    "file5.close()\n",
    "file6.close()\n",
    "file7.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(agg_cs_ch, index=phioarr, columns=reqarr)\n",
    "df.to_csv('../lookup_tables/ice_ice/oldformat_minorax_ellipsoid_flat_ch.dat', sep='\\t')\n",
    "\n",
    "df = pd.DataFrame(agg_as_ch, index=phioarr, columns=reqarr)\n",
    "df.to_csv('../lookup_tables/ice_ice/oldformat_majorax_ellipsoid_flat_ch.dat', sep='\\t')\n",
    "\n",
    "df = pd.DataFrame(agg_as_mean, index=phioarr, columns=reqarr)\n",
    "df.to_csv('../lookup_tables/ice_ice/oldformat_majorax_ellipsoid_flat_mean.dat', sep='\\t')\n",
    "\n",
    "df = pd.DataFrame(dds_mode, index=phioarr, columns=reqarr)\n",
    "df.to_csv('../lookup_tables/ice_ice/oldformat_dd_flat_mode.dat', sep='\\t')\n",
    "\n",
    "df = pd.DataFrame(major_ax_zs_ch, index=phioarr, columns=reqarr)\n",
    "df.to_csv('../lookup_tables/ice_ice/oldformat_majorax_ellipse_z_flat_ch.dat', sep='\\t')\n",
    "\n",
    "df = pd.DataFrame(major_ax_zs_mean, index=phioarr, columns=reqarr)\n",
    "df.to_csv('../lookup_tables/ice_ice/oldformat_majorax_ellipse_z_flat_mean.dat', sep='\\t')\n",
    "\n",
    "df = pd.DataFrame(depths_ch, index=phioarr, columns=reqarr)\n",
    "df.to_csv('../lookup_tables/ice_ice/oldformat_depth_flat_ch.dat', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(agg_cs_ch, index=phioarr, columns=reqarr)\n",
    "df.to_csv('../lookup_tables/ice_ice/oldformat_minorax_ellipsoid_rand_ch.dat', sep='\\t')\n",
    "\n",
    "df = pd.DataFrame(agg_as_ch, index=phioarr, columns=reqarr)\n",
    "df.to_csv('../lookup_tables/ice_ice/oldformat_majorax_ellipsoid_rand_ch.dat', sep='\\t')\n",
    "\n",
    "df = pd.DataFrame(agg_as_mean, index=phioarr, columns=reqarr)\n",
    "df.to_csv('../lookup_tables/ice_ice/oldformat_majorax_ellipsoid_rand_mean.dat', sep='\\t')\n",
    "\n",
    "df = pd.DataFrame(dds_mode, index=phioarr, columns=reqarr)\n",
    "df.to_csv('../lookup_tables/ice_ice/oldformat_dd_rand_mode.dat', sep='\\t')\n",
    "\n",
    "df = pd.DataFrame(major_ax_zs_ch, index=phioarr, columns=reqarr)\n",
    "df.to_csv('../lookup_tables/ice_ice/oldformat_majorax_ellipse_z_rand_ch.dat', sep='\\t')\n",
    "\n",
    "df = pd.DataFrame(major_ax_zs_mean, index=phioarr, columns=reqarr)\n",
    "df.to_csv('../lookup_tables/ice_ice/oldformat_majorax_ellipse_z_rand_mean.dat', sep='\\t')\n",
    "\n",
    "df = pd.DataFrame(depths_ch, index=phioarr, columns=reqarr)\n",
    "df.to_csv('../lookup_tables/ice_ice/oldformat_depth_rand_ch.dat', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
